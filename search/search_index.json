{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Cisco Live / DevNet Workshop","text":""},{"location":"#rocev2-qos-automation-on-cisco-aci","title":"RoCEv2 QoS Automation on Cisco ACI","text":"<p>Master Lab Manual</p> <p>Prepared by: David Easton Cisco Systems Engineer \u2013 UK&amp;I Date: 12<sup>th</sup> February 2026</p> <p></p>"},{"location":"#table-of-contents","title":"Table of Contents","text":""},{"location":"#introduction","title":"Introduction","text":"<ul> <li>Introduction to Lab</li> <li>Lab Outcomes &amp; Objectives</li> <li>Environment</li> <li>RoCEv2 Explanation</li> <li>Prerequisites</li> <li>Topology</li> <li>Getting Started</li> </ul>"},{"location":"#lab-exercises","title":"Lab Exercises","text":""},{"location":"#lab-1-terraform-automation-custom-module","title":"Lab 1: Terraform Automation (Custom Module)","text":"<ol> <li>Install Terraform on Tools Machine</li> <li>Terraform Concepts: Root vs. Child Modules</li> <li>Building the Terraform Root Module</li> <li>Building the Child Module (rocev2_qos)</li> <li>Script Integration &amp; Clean-Up</li> <li>Opening APIC GUI's and applying Terraform Commands</li> </ol>"},{"location":"#lab-2-terraform-nac-approach","title":"Lab 2: Terraform NAC Approach","text":"<ol> <li>NAC Environment Setup</li> <li>Understanding the Root main.tf</li> <li>NAC YAML File: qos_rocev2.nac.yaml</li> <li>Understanding qos_rocev2.nac.yaml</li> <li>NAC Script Integration</li> <li>Opening APIC GUI's and applying Terraform Commands</li> </ol>"},{"location":"#lab-3-python-automation","title":"Lab 3: Python Automation","text":"<ol> <li>Verify Python &amp; Install Dependencies</li> <li>Login to both APIC's</li> <li>Executing the Python Script</li> </ol>"},{"location":"#lab-4-bruno-api-automation","title":"Lab 4: Bruno API Automation","text":"<ol> <li>Import Collection</li> <li>Configure Environment</li> <li>Authentication</li> <li>Create QoS Policy</li> </ol>"},{"location":"#lab-5-ansible-playbooks-automation","title":"Lab 5: Ansible Playbooks Automation","text":"<ol> <li>Ansible Overview</li> <li>Setup Directory Structure</li> <li>Inventory File</li> <li>Group Variables File</li> <li>Apply QoS Playbook</li> <li>Reset QoS Playbook</li> <li>Login to APICs</li> <li>Run Playbooks</li> </ol>"},{"location":"#conclusion","title":"Conclusion","text":""},{"location":"#appendicies","title":"Appendicies","text":""},{"location":"#workshop-overview","title":"Workshop Overview","text":"<p>This comprehensive lab manual provides a structured, end-to-end workshop for configuring and automating RoCEv2 QoS across ACI fabrics. It leverages a multi-workflow approach, demonstrating automation using:</p> <ul> <li>Terraform (Custom modules and Netascode NAC)</li> <li>Python with ACI SDK</li> <li>Bruno API client</li> <li>Ansible (bonus content)</li> </ul> <p>This guide is designed for Cisco Live DevNet, dCloud, CPOC, or customer-facing training environments, aiming to equip participants with practical skills for building modern, lossless AI-ready transport environments.</p> <p>Environment Limitations</p> <p>The demonstration environment is a simulated environment and there is no actual data plane, therefore the fabrics will not establish OSPF/BGP adjacency. All configurations will be lost after a reboot of the APIC simulators. A demonstration of this completed configuration in a real environment will be shown at the end with real traffic.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to begin? Start with the Introduction to understand the lab environment and objectives.</p>"},{"location":"Conclusion/","title":"Conclusion","text":""},{"location":"Conclusion/#workshop-summary","title":"Workshop Summary","text":"<p>Congratulations on completing the RoCEv2 QoS Automation on Cisco ACI Workshop! You've explored five different approaches to automating network configuration, each with unique strengths and use cases.</p>"},{"location":"Conclusion/#what-you-accomplished","title":"What You Accomplished","text":"<p>Throughout this workshop, you:</p>"},{"location":"Conclusion/#technical-skills","title":"Technical Skills","text":"<ul> <li>\u2705 Understood RoCEv2 - Learned why RoCEv2 matters for AI/ML workloads</li> <li>\u2705 Mastered Multiple Tools - Terraform, Python, Bruno API clients, Ansible</li> <li>\u2705 Implemented QoS Policies - PFC, ECN, WRED, DSCP mapping</li> <li>\u2705 Automated Dual Fabrics - Consistent deployment across multiple APICs</li> <li>\u2705 Explored ACI REST API - Direct API interaction and understanding</li> </ul>"},{"location":"Conclusion/#automation-approaches","title":"Automation Approaches","text":"Lab Approach Key Learning Lab 1 Terraform Custom Modules Building reusable IaC from scratch Lab 2 Terraform NAC YAML-driven network as code Lab 3 Python Automation Programmatic API interaction Lab 4 Bruno API Client Visual REST API exploration Lab 5 Ansible Playbooks Procedural orchestration across multiple hosts"},{"location":"Conclusion/#choosing-the-right-tool","title":"Choosing the Right Tool","text":""},{"location":"Conclusion/#decision-matrix","title":"Decision Matrix","text":"<p>Use this guide to select the best approach for your needs:</p>"},{"location":"Conclusion/#terraform-custom-modules","title":"Terraform (Custom Modules)","text":"<p>When to use: - Need full control over configuration - Building reusable, shareable modules - Managing complex infrastructure state - Team has Terraform expertise</p> <p>Best for: Enterprise infrastructure, GitOps workflows, multi-cloud</p>"},{"location":"Conclusion/#terraform-nac","title":"Terraform (NAC)","text":"<p>When to use: - Want quick deployment with less code - Team prefers YAML over HCL - Following standard network patterns - Need to get started quickly</p> <p>Best for: Network teams new to automation, standard deployments</p>"},{"location":"Conclusion/#python","title":"Python","text":"<p>When to use: - Need complex conditional logic - Integrating with other systems/databases - Dynamic configuration based on runtime data - Custom workflows and orchestration</p> <p>Best for: Integration, advanced automation, custom tooling</p>"},{"location":"Conclusion/#bruno-api-client","title":"Bruno / API Client","text":"<p>When to use: - Learning the ACI API - Testing API calls before coding - Documenting API workflows - One-off configuration tasks</p> <p>Best for: Development, testing, learning, documentation</p>"},{"location":"Conclusion/#ansible","title":"Ansible","text":"<p>When to use: - Multi-step operational workflows - Orchestrating across many devices - Day-2 operations and remediation - When execution order and error handling matter</p> <p>Best for: Configuration management, orchestration, operational automation</p>"},{"location":"Conclusion/#real-world-applications","title":"Real-World Applications","text":""},{"location":"Conclusion/#production-deployment-pipeline","title":"Production Deployment Pipeline","text":"<p>A typical production automation workflow might combine multiple approaches:</p> <pre><code>graph LR\n    A[Bruno/Postman] --&gt;|API Testing| B[Python Scripts]\n    B --&gt;|Generate Config| C[Terraform/NAC]\n    C --&gt;|Deploy| D[ACI Fabric]\n    D --&gt;|Verify| E[Python Tests]\n    E --&gt;|Report| F[Monitoring]</code></pre> <ol> <li>Bruno - Test and document API endpoints</li> <li>Python - Generate dynamic configurations</li> <li>Terraform - Deploy with state management</li> <li>Python - Post-deployment validation</li> <li>Monitoring - Continuous verification</li> </ol>"},{"location":"Conclusion/#integration-examples","title":"Integration Examples","text":""},{"location":"Conclusion/#comparison-of-all-labs","title":"Comparison of All Labs","text":"Method Lab Pros Cons Best For Terraform Custom 1 Full control, reusable modules Steep learning curve Complex infrastructure Terraform NAC 2 Easy YAML, quick deployment Less flexible Standard patterns Python 3 Maximum flexibility, scripting More code, no state mgmt Integration, complex logic Bruno API 4 Visual, learning-friendly Manual process Testing, documentation Ansible 5 Agentless, orchestration-friendly No native state, slower Multi-APIC workflows"},{"location":"Conclusion/#best-practices-summary","title":"Best Practices Summary","text":""},{"location":"Conclusion/#general-automation","title":"General Automation","text":"<ol> <li>Start Small - Begin with simple configurations</li> <li>Test Thoroughly - Always test in non-production first</li> <li>Use Version Control - Git for all automation code</li> <li>Document Everything - README files, inline comments</li> <li>Implement Logging - Track what changes were made and when</li> </ol>"},{"location":"Conclusion/#security","title":"Security","text":"<ol> <li>Never Hardcode Credentials - Use secrets management</li> <li>Principle of Least Privilege - Minimal required permissions</li> <li>Audit Trails - Log all automation activities</li> <li>Peer Review - Code review for production changes</li> <li>Backup State Files - Maintain Terraform state backups</li> </ol>"},{"location":"Conclusion/#configuration-management","title":"Configuration Management","text":"<ol> <li>Idempotent Operations - Safe to run multiple times</li> <li>Atomic Changes - All-or-nothing deployments</li> <li>Rollback Plans - Always have an undo strategy</li> <li>Change Windows - Schedule during maintenance windows</li> <li>Validation - Automated post-deployment tests</li> </ol>"},{"location":"Conclusion/#additional-resources","title":"Additional Resources","text":""},{"location":"Conclusion/#cisco-resources","title":"Cisco Resources","text":"<ul> <li>ACI Automation Guide - Official automation documentation</li> <li>ACI Policy Model Guide - Understanding ACI object model</li> <li>DevNet ACI Learning Labs - Additional hands-on labs</li> <li>Cisco DevNet - APIs, SDKs, and developer resources</li> </ul>"},{"location":"Conclusion/#tool-documentation","title":"Tool Documentation","text":"<ul> <li>Terraform ACI Provider - Official provider docs</li> <li>Terraform NAC Module - NAC module documentation</li> <li>Python Cobra SDK - ACI Python SDK</li> <li>Bruno API Client - Bruno documentation</li> </ul>"},{"location":"Conclusion/#community","title":"Community","text":"<ul> <li>Cisco DevNet Community - Forums and discussions</li> <li>GitHub - cisco-open - Open source Cisco projects</li> <li>Terraform Registry - Modules and providers</li> </ul>"},{"location":"Conclusion/#whats-next","title":"What's Next?","text":""},{"location":"Conclusion/#expand-your-skills","title":"Expand Your Skills","text":"<ol> <li>Advanced Ansible - Explore Ansible roles, handlers, and error handling</li> <li>Multi-Fabric Orchestration - Automate across many fabrics</li> <li>Network Testing - Implement automated validation</li> <li>Monitoring Integration - Connect automation to monitoring systems</li> </ol>"},{"location":"Conclusion/#real-environment","title":"Real Environment","text":"<p>Apply what you've learned:</p> <ol> <li>Lab Environment - Practice in your own lab</li> <li>Dev/Test Fabric - Try on non-production ACI</li> <li>Production Deployment - With proper testing and change control</li> </ol>"},{"location":"Conclusion/#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Multi-tenancy Automation - Tenant provisioning workflows</li> <li>Day-2 Operations - Ongoing configuration management</li> <li>Compliance Automation - Automated policy enforcement</li> <li>Self-Service Portals - API-driven self-service for teams</li> </ul>"},{"location":"Conclusion/#final-thoughts","title":"Final Thoughts","text":""},{"location":"Conclusion/#the-power-of-automation","title":"The Power of Automation","text":"<p>Automation isn't just about saving time\u2014it's about:</p> <ul> <li>Consistency - Eliminate human error</li> <li>Scalability - Deploy to hundreds of devices</li> <li>Repeatability - Same result every time</li> <li>Velocity - Deploy faster, iterate quicker</li> <li>Compliance - Enforce standards automatically</li> </ul>"},{"location":"Conclusion/#rocev2-for-aiml","title":"RoCEv2 for AI/ML","text":"<p>As AI and ML workloads grow, RoCEv2 becomes critical:</p> <ul> <li>Lossless Operation - PFC prevents packet drops</li> <li>Low Latency - Direct memory access</li> <li>High Throughput - Maximizes GPU utilization</li> <li>Scalability - Layer 3 routing support</li> </ul> <p>By automating RoCEv2 QoS, you ensure:</p> <ul> <li>Consistent configuration across fabrics</li> <li>Rapid deployment for new GPU clusters</li> <li>Reduced errors in complex QoS policies</li> <li>Repeatable, testable infrastructure</li> </ul>"},{"location":"Conclusion/#thank-you","title":"Thank You!","text":"<p>Thank you for participating in this workshop. We hope you found it valuable and that you'll apply these automation techniques in your own environments.</p>"},{"location":"Conclusion/#feedback","title":"Feedback","text":"<p>We welcome your feedback:</p> <ul> <li>What worked well?</li> <li>What could be improved?</li> <li>What additional topics would you like to see?</li> </ul>"},{"location":"Conclusion/#stay-connected","title":"Stay Connected","text":"<ul> <li>Cisco DevNet: developer.cisco.com</li> <li>Community: Join the DevNet community forums</li> <li>Events: Attend future Cisco Live workshops</li> </ul>"},{"location":"Conclusion/#workshop-credits","title":"Workshop Credits","text":"<p>Author: David Easton Organization: Cisco Systems, Inc. Last Updated: February 2026</p> <p>Workshop Complete</p> <p>You've successfully completed all five labs and gained hands-on experience with multiple automation approaches. Keep learning, keep automating, and share your knowledge with others!</p>"},{"location":"Conclusion/#quick-reference","title":"Quick Reference","text":""},{"location":"Conclusion/#lab-summaries","title":"Lab Summaries","text":"<ul> <li>Lab 1: Terraform Custom - Custom HCL modules</li> <li>Lab 2: Terraform NAC - YAML-driven automation</li> <li>Lab 3: Python - Programmatic API access</li> <li>Lab 4: Bruno - Visual API client</li> <li>Lab 5: Ansible - Procedural playbook orchestration</li> </ul> <p>Happy Automating! \ud83d\ude80</p> <p>Optional Proceed to the Appendicies.</p>"},{"location":"appendicies/","title":"Appendicies","text":""},{"location":"appendicies/#appendix-a-terraform-installation","title":"Appendix A  - Terraform Installation","text":"<pre><code>[root@centos7-tools1 ~]# wget https://releases.hashicorp.com/terraform/1.14.0/terraform_1.14.0_linux_amd64.zip\n--2025-11-24 13:49:51--  https://releases.hashicorp.com/terraform/1.14.0/terraform_1.14.0_linux_amd64.zip\nResolving releases.hashicorp.com (releases.hashicorp.com)... 143.204.68.93, 143.204.68.39, 143.204.68.20, ...\nConnecting to releases.hashicorp.com (releases.hashicorp.com)|143.204.68.93|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 30880471 (29M) [application/zip]\nSaving to: \u2018terraform_1.14.0_linux_amd64.zip\u2019\n\n100%[======================================&gt;] 30,880,471  50.0MB/s   in 0.6s\n\n2025-11-24 13:49:52 (50.0 MB/s) - \u2018terraform_1.14.0_linux_amd64.zip\u2019 saved [30880471/30880471]\n\n[root@centos7-tools1 ~]# unzip terraform_1.14.0_linux_amd64.zip\nArchive:  terraform_1.14.0_linux_amd64.zip\ninflating: LICENSE.txt\ninflating: terraform\n[root@centos7-tools1 ~]# mv terraform /usr/local/bin/\n[root@centos7-tools1 ~]# pwd\n/root\n[root@centos7-tools1 ~]# cd /usr/local/bin/\n[root@centos7-tools1 bin]# ls\ngit            git-receive-pack    git-upload-pack  minikube\ngit-cvsserver  git-shell           kubect           terraform\ngitk           git-upload-archive  kubectl\n[root@centos7-tools1 bin]# cd terraform\n-bash: cd: terraform: Not a directory\n[root@centos7-tools1 bin]# cd terraform/\n-bash: cd: terraform/: Not a directory\n[root@centos7-tools1 bin]# terraform --version\nTerraform v1.14.0\non linux_amd64\n[root@centos7-tools1 bin]#\n[root@centos7-tools1 opt]# cd /opt\n[root@centos7-tools1 opt]#\n</code></pre>"},{"location":"appendicies/#appendix-b-python-script-explaination","title":"Appendix B  - Python Script Explaination","text":"<p>This Python script automates the configuration of RoCEv2 Quality of Service (QoS) on one or more Cisco ACI APIC controllers. It provides two functions:</p> <ul> <li>Apply a RoCEv2 no-drop QoS policy (WRED + ECN + PFC on CoS 3).</li> <li>Reset the QoS policy to default tail-drop behavior.</li> </ul> <p>The script interacts directly with the APIC REST API and supports multiple fabrics by looping through configured APIC URLs.</p> <p>Key Python Concepts Used</p> <ul> <li>REST API calls using the requests library</li> <li>XML payload submission to APIC managed object (MO) endpoints</li> <li>Command-line argument handling</li> <li>Session cookie authentication</li> <li>Per-APIC error handling</li> </ul> <p>Basic Script Configuration</p> <p>Credential Definitions - APIC username and password defined at the top of the script. - Replaced by secure storage in production.</p> <p>APIC URL List - A list of target APIC endpoints enabling multi-fabric execution.</p> <p>APIC Login Function (login()) - Authenticates to an APIC and retrieves the session cookie for API operations.</p> <p>How It Works - Posts credentials to /api/aaaLogin.json. - Returns the APIC session cookie or fails authentication.</p> <p>Role in the Script - Each APIC must authenticate before configuration changes.</p> <p>Applying the RoCEv2 QoS Policy (apply_rocev2_qos())</p> <p>Objective</p> <p>Configures class-level2 QoS to support RoCEv2 no-drop traffic using: - Priority Flow Control (PFC) - WRED congestion management - Explicit Congestion Notification (ECN)</p> <p>Key Configuration Elements in the XML Payload - QoS Class (qosClass) targeting class-level2. - Congestion Policy (qosCong) with WRED and ECN enabled. - PFC Policy (qosPfcPol) assigning CoS 3 as no-drop.</p> <p>API Interaction - Posts XML to /api/node/mo/uni.xml. - Uses the APIC session cookie. - Raises errors if rejected.</p> <p>Destroying the RoCEv2 QoS Policy (destroy_rocev2_qos())</p> <p>Purpose - Restores class-level2 QoS to default behavior.</p> <p>Reset Actions Performed - Reverts congestion handling to tail-drop - Disables ECN and PFC - Clears no-drop CoS settings</p> <p>When It\u2019s Used - Lab cleanup - Undoing Terraform deployments - Preparing a clean environment</p> <p>Command-Line Control The script expects one of the following arguments: - apply \u2013 \u2018python rocev2_qos.py apply\u2019 - destroy \u2013 \u2018python rocev2_qos.py destroy\u2019</p> <p>Main Execution Loop For each APIC: - Authenticate using login(). - Perform the selected action. - Log errors without stopping execution. This ensures failures on one fabric do not impact others.</p> <p>Benefits of This Script - Rapid, repeatable QoS deployment across fabrics. - Consistent RoCEv2 configuration. - Clear separation between apply and teardown workflows. - Human-readable XML aligned with the APIC object model.</p> <p>Summary This Python tool provides a lightweight method to configure and reset RoCEv2 QoS policies across Cisco ACI fabrics for labs, demos, and repeatable testing.</p>"},{"location":"appendicies/#appendix-c-reference-to-all-links","title":"Appendix C  - Reference to all links","text":"<ul> <li>ACI Policy Model Guide</li> <li>Cisco APIC and QoS</li> <li>ACI RoCEv2 Settings</li> <li>Wikipedia RoCE Description</li> <li>Youtube Video describing RoCEv2</li> <li>ACI Policy Model Guide</li> <li>Terraform ACI Provider Documentation</li> <li>Terraform Introduction </li> <li>ACI Terraform Provider </li> <li>ACI Terraform QoS Documentation </li> <li>ACI Modules Terraform Registry </li> <li>Devnet Lab on Terraform for ACI </li> <li>Video on Tarraform &amp; Ansible Programmability</li> <li>Cisco Netascode Site</li> <li>Netascode ACI Section</li> <li>Netascode Data Models Programmability</li> <li>Netascode ACI QoS</li> <li>Python ACI SDK (Cobra)</li> <li>Cisco ACI Python SDK Documentation</li> <li>Devnet Python ACI Examples</li> <li>Github Python ACI Examples</li> <li>Ansible ACI Community Documentation</li> <li>ACI Ansible Plugins Collection</li> <li>ACI Ansible Github Repository</li> <li>Devnet Ansible ACI Lab</li> <li>Ansible Galaxy ACI Documentation</li> </ul>"},{"location":"introduction/getting-started/","title":"Getting Started","text":""},{"location":"introduction/getting-started/#browser-recommendation","title":"Browser Recommendation","text":"<p>Important</p> <p>Please use Chrome as your local browser as this is much more likely to work with 'copy and paste' commands.</p>"},{"location":"introduction/getting-started/#accessing-the-lab-environment","title":"Accessing the Lab Environment","text":""},{"location":"introduction/getting-started/#step-1-access-your-lab-session","title":"Step 1: Access Your Lab Session","text":"<ul> <li>Click on 'View Session' from your lab dashboard</li> </ul> <ul> <li>You will see the dCloud session details</li> <li>Note your assigned IP addresses and credentials</li> </ul>"},{"location":"introduction/getting-started/#topology","title":"Topology","text":"<p>The lab environment consists of a dual-fabric ACI deployment with the following components:</p> <p></p>"},{"location":"introduction/getting-started/#network-components","title":"Network Components","text":"<ul> <li>APIC1-A Cluster - ACI Controller for Fabric A</li> <li>URL: <code>https://apic1-a.corp.pseudoco.com</code> (198.18.133.200)</li> <li> <p>Credentials: <code>admin</code> / <code>C1sco12345</code></p> </li> <li> <p>APIC1-B Cluster - ACI Controller for Fabric B  </p> </li> <li>URL: <code>https://apic1-b.corp.pseudoco.com</code> (198.18.132.200)</li> <li> <p>Credentials: <code>admin</code> / <code>C1sco12345</code></p> </li> <li> <p>Tools VM - CentOS 7 Linux machine with automation tools</p> </li> <li>Login: <code>root</code> / <code>C1sco12345</code></li> <li>Working directories:<ul> <li><code>/opt/tf</code> - Terraform custom modules</li> <li><code>/opt/nac</code> - Terraform NAC configuration</li> <li><code>/opt/ansible</code> - Ansible playbooks</li> </ul> </li> </ul>"},{"location":"introduction/getting-started/#step-2-connect-to-the-workstation","title":"Step 2: Connect to the Workstation","text":"<p>The Workstation provides a graphical desktop environment with all necessary tools pre-installed. </p> <ul> <li>To open the remote desktop connection. click the workstation with the RDP label. In this example, it's 'wkst1'. This is the required access for the ACI GUI, Python and Bruno exercises.</li> </ul> <p></p> <p>A new browser tab opens that automatically logs you into the session.</p>"},{"location":"introduction/getting-started/#step-3-connect-to-the-tools-vm","title":"Step 3 Connect to the 'tools' VM","text":"<p>There are 2 ways this 'tools' VM can be accessed</p>"},{"location":"introduction/getting-started/#option-1-within-the-workstation","title":"Option 1 - Within the Workstation:","text":"<ul> <li>Click on the Putty icon on the taskbar</li> <li>Double-click ON THE 'tools' VM</li> <li>Login with credentials: <code>root</code> / <code>C1sco12345</code></li> </ul> <p>This method is more useful to observe changes in the APIC GUI when executing the Terraform \u2018Apply\u2019, \u2018Destroy\u2019 and Ansible commands.</p>"},{"location":"introduction/getting-started/#option-2-directly-from-the-topology-view","title":"Option 2 - Directly from the Topology view:","text":"<ul> <li>Alternatively, you can SSH directly to the 'tools1' machine. </li> </ul> <p>This method is better if you prefer a direct session instead of going via the Workstation.</p> <p>The 'tools' VM is required for all Terraform and Ansible exercises to paste scripts into the VI editor. </p> <p>Script Copy &amp; Paste</p> <p>These Scripts must be fully copied and pasted from the beginning to the end i.e. not in sections as there will otherwise be indentation errors and will not work.</p> <p>Terminal Access</p> <p>You can open multiple terminal windows for different tasks. This is helpful when working with both APIC clusters simultaneously.</p>"},{"location":"introduction/getting-started/#step-4-access-apic-gui","title":"Step 4: Access APIC GUI","text":"<p>Open two browser tabs/windows:</p> <ol> <li>APIC1-A: <code>https://apic1-a.corp.pseudoco.com</code></li> <li>APIC1-B: <code>https://apic1-b.corp.pseudoco.com</code></li> </ol> <p>Login to both with credentials: <code>admin</code> / <code>C1sco12345</code></p> <p>SSL Certificate Warnings</p> <p>Accept any SSL certificate warnings - this is expected in lab environments.</p>"},{"location":"introduction/getting-started/#lab-directory-structure","title":"Lab Directory Structure","text":"<p>The automation files are organized as follows:</p> <pre><code>/opt/\n\u251c\u2500\u2500 tf/          # Terraform custom module files (Lab 1)\n\u251c\u2500\u2500 nac/         # Terraform NAC configuration (Lab 2)\n\u2514\u2500\u2500 ansible/     # Ansible playbooks (bonus material)\n</code></pre>"},{"location":"introduction/getting-started/#ready-to-begin","title":"Ready to Begin?","text":"<p>You're now ready to start the labs! Choose your path:</p> <ul> <li>Lab 1: Terraform Custom Module - Build Terraform modules from scratch</li> <li>Lab 2: Terraform NAC - Use Network as Code approach</li> <li>Lab 3: Python Automation - Python SDK automation</li> <li>Lab 4: Bruno API - REST API automation</li> <li>Lab 5: Ansible Playbooks - Build Ansible modules from scratch</li> </ul> <p>Flexible Learning Path</p> <p>While the labs are designed to be completed in sequence, each lab is self-contained. Feel free to jump to the sections that interest you most!</p>"},{"location":"introduction/overview/","title":"Introduction to Lab","text":"<p>This comprehensive lab manual provides a structured, end-to-end workshop for configuring and automating RoCEv2 QoS across ACI fabrics. It leverages a multi-workflow approach, demonstrating automation using Terraform (Custom modules and Netascode NAC), Python, Bruno, and Ansible:</p> <ul> <li>ACI Policy Model Guide</li> </ul> <p>This guide is designed for Cisco Live DevNet, dCloud, CPOC, or customer-facing training environments, aiming to equip participants with practical skills for building modern, lossless AI-ready transport environments.</p> <p>Limitations</p> <p>The demonstration environment is a simulated environment and there is no actual data plane, therefore the fabrics will not establish OSPF/BGP adjacency. All configurations will be lost after a reboot of the APIC simulators. A demonstration of this completed configuration in a real environment will be shown at the end with real traffic.</p>"},{"location":"introduction/overview/#lab-outcomes-objectives","title":"Lab Outcomes &amp; Objectives","text":"<p>Upon completing this lab, participants will be able to:</p> <ul> <li>Understand RoCEv2 QoS concepts, including WRED, ECN, PFC, and Class of Service (CoS) mapping.</li> <li>Build Terraform root and child modules from scratch for ACI configuration.</li> <li>Validate configuration changes within the APIC GUI.</li> <li>Compare and contrast manual Terraform configuration with NAC-driven Terraform.</li> <li>Execute cross-tool automation workflows using Python, Bruno, and Ansible.</li> <li>Reinforce automation repeatability across dual-fabric environments.</li> </ul> <p>This environment mimics a dual-fabric deployment, frequently utilized for AI workloads requiring robust RoCEv2 QoS.</p>"},{"location":"introduction/prerequisites/","title":"Prerequisites","text":"<p>Before beginning this workshop, participants should have:</p>"},{"location":"introduction/prerequisites/#knowledge-prerequisites","title":"Knowledge Prerequisites","text":"<ul> <li>Basic Networking Concepts</li> <li>Understanding of Layer 2/Layer 3 networking</li> <li>Familiarity with Ethernet and IP protocols</li> <li> <p>Knowledge of QoS concepts</p> </li> <li> <p>Cisco ACI Familiarity</p> </li> <li>Basic understanding of ACI architecture</li> <li>Familiarity with APIC GUI navigation</li> <li> <p>Understanding of ACI policy model (Tenants, Application Profiles, EPGs)</p> </li> <li> <p>Automation Experience</p> </li> <li>Basic command-line proficiency (Linux/Unix)</li> <li>Understanding of Infrastructure as Code (IaC) concepts</li> <li>Familiarity with at least one of: Terraform, Python, or REST APIs</li> </ul>"},{"location":"introduction/prerequisites/#software-requirements","title":"Software Requirements","text":"<p>The lab environment provides all necessary software pre-installed:</p> <ul> <li>Terraform (will be installed in Lab 1)</li> <li>Python 3.x with pip package manager</li> <li>Bruno API client</li> <li>Ansible alternative to Terraform</li> </ul>"},{"location":"introduction/prerequisites/#optional-resources","title":"Optional Resources","text":"<ul> <li>ACI Policy Model Guide</li> <li>Terraform ACI Provider Documentation</li> <li>Python ACI SDK (Cobra)</li> </ul>"},{"location":"introduction/prerequisites/#estimated-time","title":"Estimated Time","text":"<ul> <li>Total Workshop Duration: 75 minutes</li> <li>Lab 1 (Terraform Custom): 20 minutes</li> <li>Lab 2 (Terraform NAC): 20 minutes</li> <li>Lab 3 (Python): 10 minutes</li> <li>Lab 4 (Bruno API): 10 minutes</li> <li>Lab 5 (Ansible Playbooks): 15 minutes</li> </ul> <p>Lab Flexibility</p> <p>Each lab is self-contained. You can complete them in order or jump to specific sections based on your interests and time availability.</p>"},{"location":"introduction/rocev2-explained/","title":"RoCEv2 Explanation","text":""},{"location":"introduction/rocev2-explained/#what-is-rocev2","title":"What is RoCEv2?","text":"<p>RoCEv2 (RDMA over Converged Ethernet v2) enables servers\u2014especially GPU systems\u2014to exchange data directly over Ethernet with very low latency and high throughput. By bypassing the CPU and kernel network stack, it delivers the predictable performance required for AI training and inferencing.</p> <p>Unlike RoCEv1, RoCEv2 runs over Layer 3 IP networks, making it routable and scalable across large data center fabrics. This allows RDMA traffic to span multiple racks and pods, which is essential for modern AI deployments.</p> <p>AI workloads are extremely sensitive to packet loss and congestion. Even small network issues can stall GPU operations and waste expensive compute. RoCEv2 uses lossless Ethernet techniques such as PFC and ECN to prevent drops and control congestion before performance is impacted.</p> <p>RoCEv2 delivers near\u2013InfiniBand performance using standard Ethernet. This avoids the cost, complexity, and operational overhead of separate InfiniBand networks, making RoCEv2 the preferred choice for enterprise and cloud AI environments.</p>"},{"location":"introduction/rocev2-explained/#rocev1-vs-rocev2-vs-infiniband-comparison","title":"RoCEv1 vs. RoCEv2 vs. InfiniBand Comparison","text":"Feature RoCEv1 RoCEv2 InfiniBand Network Type Ethernet Ethernet Dedicated InfiniBand fabric Layer Support Layer 2 only Layer 3 (IP routable) Native fabric (non-IP) Scalability Limited High (multi-rack, multi-pod) High Routable \u274c No \u2705 Yes \u274c No (requires gateways) Lossless Operation PFC only PFC + ECN Built-in Performance Low latency, limited scale Low latency, high throughput Ultra-low latency Operational Complexity Moderate Moderate High Ecosystem Ethernet vendors Open, multi-vendor Ethernet Specialist vendors Cost per Port Medium Low\u2013Medium High Enterprise Suitability Poor Excellent Limited"},{"location":"introduction/rocev2-explained/#real-time-customer-impact-gpu-pods-at-risk","title":"Real-Time Customer Impact: GPU Pods at Risk","text":"<p>This customer scenario clearly shows the value of RoCEv2 automation. Despite a major investment in GPUs for AI inferencing, the lack of RoCEv2 meant GPUs were underutilised, directly impacting performance and business value. With only a four-hour change window and multiple large ACI fabrics to update, manual configuration was too slow and risky.</p> <p>Automating RoCEv2 features such as QoS, PFC, ECN, and traffic prioritisation using tools like Terraform, Ansible, and Python removes this risk. The network becomes predictable and repeatable, enabling consistent GPU performance across fabrics.</p> <p>In short, RoCEv2 turns the network into a core part of the AI stack, ensuring expensive GPU infrastructure delivers the performance it was designed for\u2014reliably and at scale.</p> <p> </p>"},{"location":"introduction/rocev2-explained/#extra-rocev2-resources","title":"Extra RoCEv2 Resources","text":"<ul> <li>Cisco APIC and QoS</li> <li>ACI RoCEv2 Settings</li> <li>Wikipedia RoCE Description)</li> <li>Youtube Video describing RoCEv2</li> </ul>"},{"location":"introduction/rocev2-explained/#why-rocev2-matters-for-aci","title":"Why RoCEv2 Matters for ACI","text":"<p>Cisco ACI provides comprehensive support for RoCEv2 with:</p> <ul> <li>Programmable QoS Policies - Define custom Quality of Service policies</li> <li>Priority Flow Control (PFC) - Lossless Ethernet for critical traffic</li> <li>Explicit Congestion Notification (ECN) - Proactive congestion management</li> <li>WRED Configuration - Weighted Random Early Detection for queue management</li> <li>CoS Mapping - Class of Service prioritization</li> </ul> <p>By automating these configurations, you can ensure consistent, repeatable deployments across multiple ACI fabrics.</p>"},{"location":"lab-guides/lab1-terraform-custom/apply-terraform/","title":"Opening APIC GUIs and Applying Terraform Commands","text":""},{"location":"lab-guides/lab1-terraform-custom/apply-terraform/#overview","title":"Overview","text":"<p>In this final step of Lab 1, you will apply your Terraform configuration to deploy RoCEv2 QoS policies to both ACI fabrics and verify the results in the APIC GUI.</p>"},{"location":"lab-guides/lab1-terraform-custom/apply-terraform/#step-1-open-apic-guis","title":"Step 1: Open APIC GUIs","text":"<ul> <li>Open Chrome Browser on the Desktop of the Windows Machine</li> <li>Click on shortcuts to each APIC: \u2018APIC-SF\u2019 and \u2018APIC-NY\u2019 with separate Tabs for each</li> <li>Login to each apic via admin/C1sco12345</li> </ul> <ul> <li>Click \u2018Let\u2019s Go!\u2019 in the Welcome Screen:</li> </ul> <ul> <li>Close this next Window:</li> </ul> <p>From each APIC, navigate to Fabric -&gt; Access Policies -&gt; Policies -&gt; Global -&gt; QOS Class -&gt; Level2, where the default \u2018Best Effort\u2019 QoS settings will then be displayed on the right:</p> <p></p> <p>(Optional) \u2013 Right Click on one of the Browser Tabs and select \u2018Add tab to new split view\u2019 to get the view of both APIC\u2019s:</p> <p></p>"},{"location":"lab-guides/lab1-terraform-custom/apply-terraform/#step-2-execute-terraform-init","title":"Step 2: Execute Terraform Init","text":"<p>Make sure you are in the /opt/tf/terraform directory, then issue the \u2018terraform init\u2019 command to initialize and set up the working directory by downloading the required providers, modules, and plugins so the configuration is ready to run.</p> <pre><code>cd /opt/tf/terraform\nterraform init\n</code></pre> <p>Inclusive within the output Terraform has been successfully initialized! should be seen.</p>"},{"location":"lab-guides/lab1-terraform-custom/apply-terraform/#step-3-execute-terraform-plan","title":"Step 3: Execute Terraform Plan","text":"<p>Under the same directory, issue a \u2018terraform plan\u2019 to shows what changes Terraform will make by comparing the configuration to the current infrastructure and producing an execution plan.</p> <pre><code>terraform plan\n</code></pre> <p>The end of the output should display \u2018Plan: 10 to add, 0 to change, 0 to destroy\u2019 i.e. 5 of the same objects from each APIC</p> <p>Before the next section, move the \u2018tools\u2019 Putty session Window to a different area so that changes to the GUI can be seen when executing the \u2018terraform apply\u2019 and \u2018terraform destroy\u2019 commands:</p> <p></p>"},{"location":"lab-guides/lab1-terraform-custom/apply-terraform/#step-4-execute-terraform-apply","title":"Step 4: Execute Terraform Apply","text":"<p>Under the same directory, issue a \u2018terraform apply\u2019 to executes the planned changes and update the real infrastructure to match your Terraform configuration. </p> <pre><code>terraform apply\n</code></pre> <p>Then select \u2018yes\u2019 when asked to Enter a value.  The changes should now be seen in the GUI:</p> <p>Alternatively, \u2018terraform apply \u2013auto-approve\u2019 can be used to skip the extra prompt.</p> <pre><code>terraform apply --auto-approve\n</code></pre> <p></p> <p>The end output of the terraform apply command should state:</p> <p>Apply complete! Resources: 12 added, 0 changed, 0 destroyed.</p> <p>If both tabs were to now be refreshed, the GUI at the top would now show that both APIC\u2019s are now both being managed by Terraform:</p> <p></p> <p>If you now navigate back to /opt/tf/terraform, you will notice 2 extra automatically created files:</p> <p>terraform.tfstate is Terraform\u2019s primary state file, automatically created on the first successful terraform apply, and it records the current, authoritative mapping between your configuration and real infrastructure.</p> <p>terraform.tfstate.backup is automatically created just before the state file is updated, acting as a safety copy of the previous state so you can recover if an apply or state change goes wrong.</p>"},{"location":"lab-guides/lab1-terraform-custom/apply-terraform/#step-5-execute-terraform-destroy","title":"Step 5: Execute Terraform Destroy","text":"<p>Under the same directory, issue a \u2018terraform destroy\u2019 to remove all infrastructure managed by the Terraform configuration, returning the environment to a clean state. The changes should now be seen in the GUI where each APIC are back to their original state:</p> <pre><code>terraform destroy\n</code></pre> <p>Then select \u2018yes\u2019 when asked to Enter a value.  The changes should now be seen in the GUI:</p> <p>Alternatively, \u2018terraform destroy \u2013auto-approve\u2019 can be used to skip the extra prompt:</p> <pre><code>terraform destroy --auto-approve\n</code></pre> <p></p> <p>The end output of the terraform apply command should state:  Destroy complete! Resources: 12 destroyed.</p>"},{"location":"lab-guides/lab1-terraform-custom/apply-terraform/#lab-1-complete","title":"Lab 1 Complete!","text":"<p>Congratulations! You have successfully:</p> <ul> <li>\u2705 Installed Terraform</li> <li>\u2705 Built a root module</li> <li>\u2705 Created a reusable child module</li> <li>\u2705 Deployed RoCEv2 QoS to dual ACI fabrics</li> <li>\u2705 Verified configuration in APIC GUI</li> </ul>"},{"location":"lab-guides/lab1-terraform-custom/apply-terraform/#next-steps","title":"Next Steps","text":"<p>Ready to explore a different approach? Proceed to Lab 2: Terraform NAC to learn about Network as Code with YAML-driven configuration.</p>"},{"location":"lab-guides/lab1-terraform-custom/child-module/","title":"Building the Child Module (rocev2_qos)","text":""},{"location":"lab-guides/lab1-terraform-custom/child-module/#overview","title":"Overview","text":"<p>In this section, you will create a reusable Terraform child module that implements RoCEv2 QoS configuration for ACI. This module can be called multiple times to deploy the same configuration to different fabrics or tenants.</p>"},{"location":"lab-guides/lab1-terraform-custom/child-module/#create-module-directory","title":"Create Module Directory","text":"<p>Create the module directory structure:</p> <pre><code>cd /opt/tf/terraform\nmkdir modules\ncd modules\nmkdir rocev2_qos\ncd rocev2_qos\n</code></pre> <p>The child main.tf file contains the implementation logic for the RoCEv2 QoS configuration. While the root main.tf decides which APICs to target and how many times to call this module, the child main.tf defines what is built on the ACI fabric.</p> <p>Create the child main.tf file by executing the command \u2018vi main.tf\u2019 and pasting the following content:</p> <pre><code>vi main.tf\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/child-module/#step-1-create-maintf","title":"Step 1: Create <code>main.tf</code>","text":"<p>Vi Editor Tips</p> <p>Press i to insert text, then copy and paste all the content below.</p> <p>Define the module's input variables:</p> <pre><code># Declaring the ACI Provider Requirement (ciscodevnet/aci), allowing it to be reused while clearly stating its dependency:\n\nterraform {\n  required_providers {\n    aci = {\n      source = \"ciscodevnet/aci\"\n    }\n  }\n}\n\n# Creating the QoS Class (Level 2) with class_name = \"qosClass\" and dn = \"uni/infra/qosinst-default/class-level2\". enabling it (admin = \"enabled\") and assigning priority level2. This forms the foundation for congestion and PFC policies:\n\nresource \"aci_rest_managed\" \"qos_class_level2\" {\n  class_name = \"qosClass\"\n  dn         = \"uni/infra/qosinst-default/class-level2\"\n  content = {\n    admin = \"enabled\"\n    prio  = \"level2\"\n  }\n}\n\n# Applies congestion management settings to the QoS class, enabling WRED and ECN to detect and signal congestion for this traffic class.\n\nresource \"aci_rest_managed\" \"qos_class_congestion\" {\n  class_name = \"qosCong\"\n  dn         = \"${aci_rest_managed.qos_class_level2.dn}/cong\"\n  content = {\n    algo             = \"wred\"\n    wredMaxThreshold = \"60\"\n    wredMinThreshold = \"40\"\n    wredProbability  = \"0\"\n    ecn              = \"enabled\"\n    forwardNonEcn    = \"enabled\"\n  }\n}\n\n# Creating/Modifying the QoS Scheduling Policy (child of qosClass).\n\nresource \"aci_rest_managed\" \"qos_class_scheduling\" {\n  class_name = \"qosSched\"\n  dn                 = \"${aci_rest_managed.qos_class_level2.dn}/sched\"\n  content = {\n    bw = \"60\"\n  }\n}\n\n# This script configures Priority Flow Control (PFC) by calling the APIC APIs directly. A null_resource runs curl commands to log into the APIC and post an XML payload for the specified noDropCos. \n\nresource \"null_resource\" \"enable_pfc_via_curl\" {\n  provisioner \"local-exec\" {\n    command = &lt;&lt;EOT\ncurl -sk -X POST ${var.apic_url}/api/aaaLogin.json \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"aaaUser\":{\"attributes\":{\"name\":\"${var.admin_username}\",\"pwd\":\"${var.admin_password}\"}}}' \\\n  -c apic-cookie.txt\n\ncurl -sk -X POST ${var.apic_url}/api/node/mo/uni.xml \\\n  -H \"Content-Type: application/xml\" \\\n  -d '&lt;qosClass admin=\"enabled\" dn=\"uni/infra/qosinst-default/class-level2\" prio=\"level2\"&gt;\n         &lt;qosPfcPol name=\"default\" noDropCos=\"${var.cos}\" adminSt=\"yes\" enableScope=\"fabric\"/&gt;\n       &lt;/qosClass&gt;' \\\n  -b apic-cookie.txt\nEOT\n  }\n}\n\n# Two null_resource cleanup hooks run during terraform destroy, calling a shared reset_qos.sh script to reset QoS on both APICs and leave the lab environment clean\n\nresource \"null_resource\" \"reset_qos_apic1a\" {\n  provisioner \"local-exec\" {\n    when    = destroy\n    command = \"bash ${path.module}/../../scripts/reset_qos.sh https://apic1-a.corp.pseudoco.com\"\n  }\n}\n\nresource \"null_resource\" \"reset_qos_apic1b\" {\n  provisioner \"local-exec\" {\n    when    = destroy\n    command = \"bash ${path.module}/../../scripts/reset_qos.sh https://apic1-b.corp.pseudoco.com\"\n  }\n}\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/child-module/#save-the-file","title":"Save the File","text":"<p>Save the file by pressing Esc, then typing :wq!</p>"},{"location":"lab-guides/lab1-terraform-custom/child-module/#verify-the-file","title":"Verify the File","text":"<p>Once outside the vi editor, the file can be verified by typing:</p> <pre><code>cat main.tf\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/child-module/#step-2-create-variablestf","title":"Step 2: Create <code>variables.tf</code>","text":"<p>This child variables.tf file defines the input parameters that the RoCEv2 QoS module expects from the root module. While the root variables.tf captures values from the lab user, the child variables.tf describes what this module needs to build the configuration on a given APIC.</p> <p>Create the child variables.tf file by executing the command \u2018vi variables.tf\u2019 and pasting the following content:</p> <pre><code>vi variables.tf\n</code></pre> <p>Vi Editor Tips</p> <p>Press i to insert text, then copy and paste all the content below.</p> <p>Implement the RoCEv2 QoS resources:</p> <pre><code>#  Class of Service value (default cos3) used for no-drop RoCEv2 traffic, which is inserted into the XML payload for PFC:\n\nvariable \"cos\" {\n  description = \"Class of service value\"\n  type        = string\n  default     = \"cos3\"\n}\n\n# apic_url, admin_username, and admin_password define how Terraform connects to the APIC. These values are provided by the root module, allowing the same module to be reused across multiple fabrics. The password is marked sensitive to prevent accidental exposure:\n\nvariable \"admin_username\" {\n  type = string\n}\n\nvariable \"admin_password\" {\n  type      = string\n  sensitive = true\n}\n\nvariable \"apic_url\" {\n  type = string\n}\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/child-module/#save-the-file_1","title":"Save the File","text":"<p>Save the file by pressing Esc, then typing :wq!</p>"},{"location":"lab-guides/lab1-terraform-custom/child-module/#verify-the-file_1","title":"Verify the File","text":"<p>Once outside the vi editor, the file can be verified by typing:</p> <pre><code>cat variables.tf\n</code></pre> <p>In summary, the child module main.tf focuses entirely on what QoS and RoCEv2-related configuration is applied to the fabrics.</p>"},{"location":"lab-guides/lab1-terraform-custom/child-module/#module-structure","title":"Module Structure","text":"<p>Your module directory should now contain:</p> <pre><code>/opt/tf/modules/rocev2_qos/\n\u251c\u2500\u2500 main.tf\n\u251c\u2500\u2500 variables.tf\n</code></pre> <p>Module Complete</p> <p>Your reusable RoCEv2 QoS module is now ready to be deployed!</p>"},{"location":"lab-guides/lab1-terraform-custom/child-module/#next-steps","title":"Next Steps","text":"<p>Proceed to Script Integration to create helper scripts for managing the configuration.</p>"},{"location":"lab-guides/lab1-terraform-custom/install-terraform/","title":"Install Terraform on Tools Machine","text":""},{"location":"lab-guides/lab1-terraform-custom/install-terraform/#overview","title":"Overview","text":"<p>In this section, you will install Terraform on the CentOS 7 Tools VM. Terraform will be used to automate the deployment of RoCEv2 QoS policies on both ACI fabrics.</p>"},{"location":"lab-guides/lab1-terraform-custom/install-terraform/#prerequisites","title":"Prerequisites","text":"<ul> <li>Access to the Tools VM as root</li> <li>Internet connectivity (for downloading Terraform)</li> </ul>"},{"location":"lab-guides/lab1-terraform-custom/install-terraform/#step-1-download-terraform","title":"Step 1: Download Terraform","text":"<p>First, navigate to the working directory and download the Terraform binary:</p> <pre><code>cd /opt/tf\nwget https://releases.hashicorp.com/terraform/1.14.0/terraform_1.14.0_linux_amd64.zip\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/install-terraform/#step-2-extract-and-install-terraform","title":"Step 2: Extract and Install Terraform","text":"<p>Extract the Terraform binary and move it to <code>/usr/local/bin</code>:</p> <pre><code>unzip terraform_1.14.0_linux_amd64.zip\nmv terraform /usr/local/bin/\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/install-terraform/#step-3-verify-installation","title":"Step 3: Verify Installation","text":"<p>Verify that Terraform is installed correctly:</p> <pre><code>terraform --version\n</code></pre> <p>Expected output:</p> <pre><code>Terraform v1.14.0\non linux_amd64\n</code></pre> <p>Installation Complete</p> <p>Terraform is now installed and ready to use! A more verbose output of this can be seen in Appendix A.</p>"},{"location":"lab-guides/lab1-terraform-custom/install-terraform/#next-steps","title":"Next Steps","text":"<p>Now that Terraform is installed, proceed to Terraform Concepts to understand root and child modules before building your configuration.</p>"},{"location":"lab-guides/lab1-terraform-custom/introduction-to-terraform/","title":"Lab 1: Opening APIC GUIs and Applying Terraform Commands","text":""},{"location":"lab-guides/lab1-terraform-custom/introduction-to-terraform/#overview","title":"Overview","text":"<p>HashiCorp Terraform (often called classic Terraform, to distinguish it from NAC/Netascode) is a widely adopted Infrastructure-as-Code tool because it offers a consistent, declarative way to manage infrastructure across many platforms. Engineers describe the desired end state using HCL, and Terraform automatically works out dependencies, ordering, and the minimum set of changes required.</p> <p>One of Terraforms biggest strengths is its provider ecosystem. Thousands of official and community providers allow it to manage public cloud, private cloud, networking, security, SaaS, and on-prem infrastructure from a single workflow. Features like state management, plan/apply, drift detection, and reusable modules make it well suited to large, repeatable, and auditable environments.</p> <p>Compared to other IaC tools, Terraform is highly platform-agnostic. Configuration tools such as Ansible are excellent for procedural tasks and day-2 operations, but they lack Terraforms built-in state awareness and drift tracking:</p>"},{"location":"lab-guides/lab1-terraform-custom/introduction-to-terraform/#optional-resources","title":"Optional Resources","text":"<ul> <li>Terraform Introduction - General overview of Terraform from the Hashicorp Website.</li> <li>ACI Terraform Provider - Central place on the Terraform Registry where all ACI resources and data sources are documented. Shows the full list of objects that can be managed in ACI (tenants, EPGs, BDs, VRFs, contracts, filters, etc.) and how to use them for .tf files.</li> <li>ACI Terraform QoS Documentation) \u2013 Specific modules for QoS</li> <li>ACI Modules Terraform Registry - to browse a large number of ACI modules that package common use-cases and patterns for ACI automation (often reusable building blocks) in Github.</li> <li>Devnet Lab on Terraform for ACI - optional extra Lab to walk through for a later date.</li> <li>Video on Tarraform &amp; Ansible Programmability</li> </ul>"},{"location":"lab-guides/lab1-terraform-custom/introduction-to-terraform/#next-steps","title":"Next Steps","text":"<p>Proceed to Install Terraform.</p>"},{"location":"lab-guides/lab1-terraform-custom/root-module/","title":"Building the Terraform Root Module","text":""},{"location":"lab-guides/lab1-terraform-custom/root-module/#overview","title":"Overview","text":"<p>In this section, you will build the root Terraform module that orchestrates the deployment of RoCEv2 QoS policies to both ACI fabrics (APIC1-A and APIC1-B).</p>"},{"location":"lab-guides/lab1-terraform-custom/root-module/#working-directory","title":"Working Directory","text":"<p>Ensure you're in the correct directory:</p> <pre><code>cd /opt/\nmkdir tf\ncd tf\nmkdir terraform\ncd terraform\n</code></pre> <p>Create the root main.tf file by executing the command \u2018vi main.tf\u2019 and pasting the following content:</p> <pre><code>vi main.tf\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/root-module/#step-1-create-maintf","title":"Step 1: Create <code>main.tf</code>","text":"<p>Vi Editor Tips</p> <p>Press i to insert text, then copy and paste all the content below.</p> <pre><code># Declaring the Required Provider - The terraform block specifies the required ACI provider, ensuring consistency and repeatability by pinning the version.\n\nterraform {\n  required_providers {\n    aci = {\n      source  = \"ciscodevnet/aci\"\n      version = \"~&gt; 2.16.0\"\n    }\n  }\n}\n\n# Two aci provider blocks are defined\u2014one for each APIC cluster\u2014using aliases to distinguish the fabrics. Each provider uses variables for the APIC URL and credentials, allowing Terraform to manage both ACI fabrics in a single run.\n\nprovider \"aci\" {\n  alias    = \"apic1-a\"\n  username = var.admin_username\n  password = var.admin_password\n  url      = \"https://apic1-a.corp.pseudoco.com\"\n  insecure = true\n}\n\nprovider \"aci\" {\n  alias    = \"apic1-b\"\n  username = var.admin_username\n  password = var.admin_password\n  url      = \"https://apic1-b.corp.pseudoco.com\"\n  insecure = true\n}\n\n# The rocev2_qos module is reused for each APIC, with provider binding and inputs adjusted per fabric to ensure consistent QoS configuration.\n\nmodule \"qos_apic1_a\" {\n  source    = \"./modules/rocev2_qos\"\n  providers = { aci = aci.apic1-a }\n\n  admin_username = var.admin_username\n  admin_password = var.admin_password\n  apic_url       = \"https://apic1-a.corp.pseudoco.com\"\n  cos            = var.cos\n}\n\nmodule \"qos_apic1_b\" {\n  source    = \"./modules/rocev2_qos\"\n  providers = { aci = aci.apic1-b }\n\n  admin_username = var.admin_username\n  admin_password = var.admin_password\n  apic_url       = \"https://apic1-b.corp.pseudoco.com\"\n  cos            = var.cos\n}\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/root-module/#save-the-file","title":"Save the File","text":"<p>Save the file by pressing Esc, then typing :wq!</p>"},{"location":"lab-guides/lab1-terraform-custom/root-module/#verify-the-file","title":"Verify the File","text":"<p>Once outside the vi editor, the file can be verified by typing:</p> <pre><code>cat main.tf\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/root-module/#step-2-create-variablestf","title":"Step 2: Create <code>variables.tf</code>","text":"<p>Create the root variables.tf file by executing the command \u2018vi variables.tf\u2019 and pasting the following content:</p> <pre><code>vi variables.tf\n</code></pre> <p>Vi Editor Tips</p> <p>Press i to insert text, then copy and paste all the content below.</p> <p>Define the input variables:</p> <pre><code># Defining the Username and Password Variables:\n\nvariable \"admin_username\" {\n  type    = string\n  default = \"admin\"\n}\n\nvariable \"admin_password\" {\n  type      = string\n  sensitive = true\n  default   = \"C1sco12345\"\n}\n\n# Defining the RoCEv2 Policy Inputs like cos, which allow users to set policy behavior without editing Terraform logic:\n\nvariable \"cos\" {\n  description = \"Class of Service value (e.g., cos3, cos4)\"\n  type        = string\n  default     = \"cos3\"\n}\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/root-module/#save-the-file_1","title":"Save the File","text":"<p>Save the file by pressing Esc, then typing :wq!</p>"},{"location":"lab-guides/lab1-terraform-custom/root-module/#verify-the-file_1","title":"Verify the File","text":"<p>Once outside the vi editor, the file can be verified by typing:</p> <pre><code>cat variables.tf\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/root-module/#directory-structure","title":"Directory Structure","text":"<p>Your directory should now look like this:</p> <pre><code>/opt/tf/\n\u251c\u2500\u2500 main.tf\n\u251c\u2500\u2500 providers.tf\n\u251c\u2500\u2500 variables.tf\n\u251c\u2500\u2500 terraform.tfvars\n\u251c\u2500\u2500 outputs.tf\n\u2514\u2500\u2500 modules/\n    \u2514\u2500\u2500 rocev2_qos/       # (Created in next step)\n</code></pre> <p>Root Module Complete</p> <p>Your root module is now ready! It will deploy the same RoCEv2 QoS configuration to both ACI fabrics.</p>"},{"location":"lab-guides/lab1-terraform-custom/root-module/#next-steps","title":"Next Steps","text":"<p>Proceed to Building the Child Module to create the reusable RoCEv2 QoS module.</p>"},{"location":"lab-guides/lab1-terraform-custom/script-integration/","title":"Script Integration &amp; Clean-Up","text":""},{"location":"lab-guides/lab1-terraform-custom/script-integration/#overview","title":"Overview","text":"<p>Terraform is excellent for declarative provisioning, but certain cleanup actions or tasks are:</p> <ul> <li>Procedural</li> <li>Easier to express in shell script</li> <li>Specific to lab environments</li> <li>Not easily handled by ACI provider resources</li> </ul> <p>For these tasks, Terraform uses the null_resource with a local-exec provisioner.</p> <p>The scripts folder provides a clean, reusable location for external helper scripts that Terraform can call during certain lifecycle events (e.g., terraform destroy). This reset_qos.sh script provides a consistent and automated way to reset QoS configuration on the APIC.</p> <p>In this section, you will create helper scripts to streamline Terraform operations and clean up configurations when needed.</p>"},{"location":"lab-guides/lab1-terraform-custom/script-integration/#create-cleanup-script","title":"Create Cleanup Script","text":"<p>Create a scripts folder and script file to destroy the Terraform-managed infrastructure:</p> <pre><code>cd /opt/tf/terraform\nmkdir scripts\ncd scripts\nvi reset_qos.sh\n</code></pre> <p>Vi Editor Tips</p> <p>Press i to insert text, then copy and paste all the content below.</p> <p>Add the following content:</p> <pre><code>#!/bin/bash\nset -e\n\nAPIC_URL=\"$1\"\nUSERNAME=\"admin\"\nPASSWORD=\"C1sco12345\"\nCOOKIE_FILE=\"/tmp/apic-cookie-$$.txt\"\n\necho \"Resetting QoS configuration on $APIC_URL...\"\n\n# Logging In to APIC: The script authenticates to the APIC using the AAA login API and stores the session token in the unique cookie file:\n\ncurl -sk -X POST \"$APIC_URL/api/aaaLogin.json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"aaaUser\\\":{\\\"attributes\\\":{\\\"name\\\":\\\"$USERNAME\\\",\\\"pwd\\\":\\\"$PASSWORD\\\"}}}\" \\\n  -c \"$COOKIE_FILE\"\n\n# Reset QoS Class Level2 config (Tail-drop + PFC disabled)\n\ncurl -sk -X POST \"$APIC_URL/api/node/mo/uni.xml\" \\\n  -H \"Content-Type: application/xml\" \\\n  -d '&lt;qosClass admin=\"enabled\" dn=\"uni/infra/qosinst-default/class-level2\" prio=\"level2\"&gt;\n         &lt;qosCong algo=\"tail-drop\" ecn=\"disabled\"/&gt;\n         &lt;qosPfcPol name=\"default\" adminSt=\"no\" noDropCos=\"\"/&gt;\n       &lt;/qosClass&gt;' \\\n  -b \"$COOKIE_FILE\"\n\n\n# Reset QoS Class Level2 Bandwidth allocated to 20%\n\ncurl -sk -X POST \"$APIC_URL/api/node/mo/uni/infra/qosinst-default/class-level2/sched.json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"qosSched\":{\"attributes\":{\"dn\":\"uni/infra/qosinst-default/class-level2/sched\",\"bw\":\"20\"},\"children\":[]}}' \\\n  -b \"$COOKIE_FILE\"\n\nrm -f \"$COOKIE_FILE\"\n\necho \"Reset complete.\"\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/script-integration/#save-the-file","title":"Save the File","text":"<p>Save the file by pressing Esc, then typing :wq!</p>"},{"location":"lab-guides/lab1-terraform-custom/script-integration/#verify-the-file","title":"Verify the File","text":"<p>Once outside the vi editor, the file can be verified by typing:</p> <pre><code>cat reset_qos.sh\n</code></pre> <p>Make the script executable:</p> <pre><code>chmod +x reset_qos.sh\n</code></pre> <p>Optional</p> <p>You can test the script manually though it's primarily for terraform destroy</p> <pre><code>bash reset_qos.sh https://apic1-a.corp.pseudoco.com \n</code></pre> <pre><code>bash reset_qos.sh https://apic1-b.corp.pseudoco.com \n</code></pre> <p>This ensures that any RoCEv2-specific configuration applied by the lab is removed cleanly. Cleaning Up the Cookie File and Exiting: The temporary cookie file is deleted, and a completion message is printed.</p>"},{"location":"lab-guides/lab1-terraform-custom/script-integration/#next-steps","title":"Next Steps","text":"<p>Proceed to Apply Terraform to deploy your RoCEv2 QoS configuration to both ACI fabrics.</p>"},{"location":"lab-guides/lab1-terraform-custom/terraform-concepts/","title":"Terraform Concepts - Root vs. Child Modules","text":""},{"location":"lab-guides/lab1-terraform-custom/terraform-concepts/#overview","title":"Overview","text":"<p>Understanding Terraform module architecture is essential for building maintainable, reusable infrastructure code. This section explains the key concepts before you build your own modules.</p>"},{"location":"lab-guides/lab1-terraform-custom/terraform-concepts/#root-module","title":"Root Module","text":"<p>The root module is the main Terraform configuration directory where you run <code>terraform</code> commands. It typically contains:</p> <ul> <li><code>main.tf</code> - Primary resource definitions and module calls</li> <li><code>variables.tf</code> - Input variable declarations</li> <li><code>terraform.tfvars</code> - Variable values</li> <li><code>outputs.tf</code> - Output value declarations</li> <li><code>providers.tf</code> - Provider configuration</li> </ul>"},{"location":"lab-guides/lab1-terraform-custom/terraform-concepts/#purpose","title":"Purpose","text":"<p>The root module orchestrates the overall deployment by:</p> <ul> <li>Calling child modules with specific parameters</li> <li>Managing provider configurations</li> <li>Defining top-level resources</li> <li>Setting input variables for the entire infrastructure</li> </ul>"},{"location":"lab-guides/lab1-terraform-custom/terraform-concepts/#child-modules","title":"Child Modules","text":"<p>Child modules are reusable components that encapsulate related resources. They are called from the root module and can be reused across different projects.</p>"},{"location":"lab-guides/lab1-terraform-custom/terraform-concepts/#benefits-of-child-modules","title":"Benefits of Child Modules","text":"<ul> <li>Reusability - Write once, use many times</li> <li>Abstraction - Hide complex configurations behind simple interfaces</li> <li>Maintainability - Update logic in one place</li> <li>Consistency - Ensure standardized configurations across deployments</li> </ul>"},{"location":"lab-guides/lab1-terraform-custom/terraform-concepts/#root-vs-child-module-comparison","title":"Root vs Child Module Comparison","text":"Feature Root Module Child Module Purpose Entry point for Terraform Reusable configuration logic Location Top-level project directory Subdirectory or separate module repo Terraform Commands init, plan, apply run here Not run directly RoutResponsibility Orchestrates the deployment Defines how resources are built Reusability Single per project Reused multiple times with inputs Typical Usage Passes variables and providers Creates and manages resources"},{"location":"lab-guides/lab1-terraform-custom/terraform-concepts/#module-structure","title":"Module Structure","text":"<p>A typical child module contains:</p> <pre><code>modules/\n\u2514\u2500\u2500 rocev2_qos/\n    \u251c\u2500\u2500 main.tf          # Resource definitions\n    \u251c\u2500\u2500 variables.tf     # Input variables\n    \u251c\u2500\u2500 outputs.tf       # Output values\n    \u2514\u2500\u2500 README.md        # Module documentation\n</code></pre>"},{"location":"lab-guides/lab1-terraform-custom/terraform-concepts/#our-lab-architecture","title":"Our Lab Architecture","text":"<p>In this lab, you will build:</p> <ol> <li>Root Module - Orchestrates deployment to both APIC clusters</li> <li>rocev2_qos Child Module - Implements the RoCEv2 QoS configuration</li> </ol> <p>This structure allows you to:</p> <ul> <li>Deploy the same QoS policy to multiple fabrics</li> <li>Maintain a single source of truth for the configuration</li> <li>Easily modify the policy across all deployments</li> </ul> <p>Module Best Practices</p> <ul> <li>Keep modules focused on a single responsibility</li> <li>Use meaningful variable names</li> <li>Document your modules thoroughly</li> <li>Version your modules for production use</li> </ul>"},{"location":"lab-guides/lab1-terraform-custom/terraform-concepts/#next-steps","title":"Next Steps","text":"<p>Now that you understand module architecture, proceed to Building the Root Module to create your configuration.</p>"},{"location":"lab-guides/lab2-terraform-nac/apply-terraform/","title":"Deploying NAC Configuration","text":""},{"location":"lab-guides/lab2-terraform-nac/apply-terraform/#overview","title":"Overview","text":"<p>In this final step of Lab 2, you will deploy the NAC YAML configuration to both ACI fabrics and verify the results.</p>"},{"location":"lab-guides/lab2-terraform-nac/apply-terraform/#step-1-open-both-apic-simulators","title":"Step 1: Open both APIC Simulators","text":"<ul> <li>Open Chrome Browser on the Desktop of the Windows Machine</li> <li>Click on shortcuts to each APIC: \u2018APIC-SF\u2019 and \u2018APIC-NY\u2019 with separate Tabs for each</li> <li>Login to each APIC via admin/C1sco12345</li> </ul> <p>From each APIC, navigate to Fabric -&gt; Access Policies -&gt; Policies -&gt; Global -&gt; QOS Class -&gt; Level2, where the default \u2018Best Effort\u2019 QoS settings will then be displayed on the right:</p> <p></p> <p>(Optional) \u2013 Right Click on one of the Browser Tabs and select \u2018Add tab to new split view\u2019 to get the view of both APIC\u2019s:</p> <p></p>"},{"location":"lab-guides/lab2-terraform-nac/apply-terraform/#step-2-execute-terraform-init","title":"Step 2: Execute Terraform Init","text":"<p>Navigate back to /opt/nac/nac-aci-simple-example, then issue the \u2018terraform init\u2019 command to initialize and set up the working directory by downloading the required providers, modules, and plugins so the configuration is ready to run.</p> <pre><code>cd /opt/nac/nac-aci-simple-example/\nterraform init\n</code></pre> <p>Inclusive within the output Terraform has been successfully initialized! should be seen.</p>"},{"location":"lab-guides/lab2-terraform-nac/apply-terraform/#step-3-execute-terraform-plan","title":"Step 3: Execute Terraform Plan","text":"<p>Under the same directory, issue a \u2018terraform plan\u2019 to show what changes Terraform will make by comparing the configuration to the current infrastructure and producing an execution plan.</p> <pre><code>terraform plan\n</code></pre> <p>The end of the output should display \u2018Plan: 20 to add, 0 to change, 0 to destroy\u2019 i.e. 10 of the same objects from each APIC</p> <p>Observe that NAC is slower because it adds an abstraction layer that translates YAML intent into multiple Terraform resources, increasing processing and API calls. Classic Terraform talks directly to the provider with fewer layers, so plans and applies run faster.</p> <p>Before the next section, move the \u2018tools\u2019 Putty session Window to a different area so that changes to the GUI can be seen when executing the \u2018terraform apply\u2019 and \u2018terraform destroy\u2019 commands:</p> <p></p>"},{"location":"lab-guides/lab2-terraform-nac/apply-terraform/#step-4-execute-terraform-apply","title":"Step 4: Execute Terraform Apply","text":"<p>Under the same directory, issue a \u2018terraform apply\u2019 to executes the planned changes and update the real infrastructure to match your Terraform configuration. </p> <pre><code>terraform apply\n</code></pre> <p>Then select \u2018yes\u2019 when asked to Enter a value.  The changes should now be seen in the GUI:</p> <p>Alternatively, \u2018terraform apply \u2013auto-approve\u2019 can be used to skip the extra prompt:</p> <pre><code>terraform apply --auto-approve\n</code></pre> <p></p> <p>The end output of the terraform apply command should state:  Apply complete! Resources: 20 added, 0 changed, 0 destroyed.</p> <p>If both tabs were to now be refreshed, the GUI at the top would now show that both APIC\u2019s are now both being managed by Terraform:</p> <p></p> <p>You will notice 2 extra automatically created files under /opt/nac/nac-aci-simple-example/</p> <p>terraform.tfstate is Terraform\u2019s primary state file, automatically created on the first successful terraform apply, and it records the current, authoritative mapping between your configuration and real infrastructure.</p> <p>terraform.tfstate.backup is automatically created just before the state file is updated, acting as a safety copy of the previous state so you can recover if an apply or state change goes wrong.</p>"},{"location":"lab-guides/lab2-terraform-nac/apply-terraform/#step-5-execute-terraform-destroy","title":"Step 5: Execute Terraform Destroy","text":"<p>Under the same directory, issue a \u2018terraform destroy\u2019 to remove all infrastructure managed by the Terraform configuration, returning the environment to a clean state. The changes should now be seen in the GUI where each APIC are back to their original state.</p> <p><pre><code>terraform destroy\n</code></pre> Then select \u2018yes\u2019 when asked to Enter a value.  The changes should now be seen in the GUI:</p> <p>Alternatively, \u2018terraform destroy \u2013-auto-approve\u2019 can be used to skip the extra prompt:</p> <pre><code>terraform destroy --auto-approve\n</code></pre> <p></p> <p>The end output of the terraform apply command should state:  Destroy complete! Resources: 20 destroyed.</p>"},{"location":"lab-guides/lab2-terraform-nac/apply-terraform/#lab-2-complete","title":"Lab 2 Complete!","text":"<p>Congratulations! You have successfully:</p> <ul> <li>\u2705 Set up NAC environment</li> <li>\u2705 Created YAML configuration</li> <li>\u2705 Deployed via NAC to dual fabrics</li> <li>\u2705 Compared NAC vs. Custom modules</li> </ul>"},{"location":"lab-guides/lab2-terraform-nac/apply-terraform/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>NAC simplifies configuration - YAML is more accessible than HCL</li> <li>Same result, different approach - Both labs achieve identical ACI config</li> <li>Choose the right tool - Custom modules for flexibility, NAC for speed</li> </ol>"},{"location":"lab-guides/lab2-terraform-nac/apply-terraform/#next-steps","title":"Next Steps","text":"<p>Ready to try a different approach? Proceed to Lab 3: Python Automation to implement RoCEv2 QoS using Python and the ACI SDK.</p>"},{"location":"lab-guides/lab2-terraform-nac/introduction-to-nac/","title":"NAC Environment Setup","text":"<p>Cisco Netascode provides a higher-level, intent-driven approach to network automation. Instead of managing low-level Terraform resources and dependencies, engineers define the desired network state using structured inputs such as YAML, while Cisco-curated modules handle the underlying configuration.</p> <p></p> <p>This approach reduces complexity for platforms such as ACI, SD-WAN, ISE, and Meraki by embedding validation and best practices directly into the workflow. The result is faster, more consistent deployments with a lower risk of configuration errors.</p> <p>Traditional Terraform offers greater flexibility and multi-vendor reach but requires more manual effort and expertise. Netascode trades some low-level control for speed, consistency, and reliability, making it well suited to standardised, Cisco-centric environments at scale.</p> <ul> <li>Cisco Netascode Site</li> <li>Netascode ACI Section</li> <li>Netascode Data Models Programmability</li> <li>Netascode ACI QoS</li> </ul> <p>This section demonstrates using the Netascode Terraform module to deploy an equivalent RoCEv2 QoS configuration using a declarative, YAML-driven approach. The module maps the YAML intent to the correct ACI attributes, removing the need to manage XML payloads or REST API calls directly.</p> <p>In this model, the YAML file defines what the RoCEv2 QoS policy should look like, while Netascode and Terraform act as the engine that translates that intent into actual APIC configuration:</p> <p>Please ensure Terraform is already installed from Lab 1</p> <p>If you have gone straight to this Lab without having completed Lab 1, please go straight to the 'Install Terraform' section.</p>"},{"location":"lab-guides/lab2-terraform-nac/introduction-to-nac/#next-steps","title":"Next Steps","text":"<p>Proceed to NAC Setup to learn about Network as Code with YAML-driven configuration.</p>"},{"location":"lab-guides/lab2-terraform-nac/nac-setup/","title":"NAC Environment Setup","text":""},{"location":"lab-guides/lab2-terraform-nac/nac-setup/#overview","title":"Overview","text":"<p>Lab 2 demonstrates the Network as Code (NAC) approach using the Cisco Netascode Terraform provider. Unlike Lab 1's custom modules, NAC uses YAML configuration files to define infrastructure, making it more accessible to network engineers.</p>"},{"location":"lab-guides/lab2-terraform-nac/nac-setup/#what-is-network-as-code-nac","title":"What is Network as Code (NAC)?","text":"<p>Network as Code is an approach that:</p> <ul> <li>Uses YAML instead of HCL for configuration</li> <li>Provides higher-level abstractions for network concepts</li> <li>Enables non-programmers to define infrastructure</li> <li>Maintains Terraform's state management benefits</li> </ul>"},{"location":"lab-guides/lab2-terraform-nac/nac-setup/#nac-vs-custom-modules","title":"NAC vs. Custom Modules","text":"Aspect Custom Modules (Lab 1) NAC (Lab 2) Configuration Language HCL (HashiCorp Configuration Language) YAML Skill Requirement Terraform expertise required Network knowledge sufficient Abstraction Level Low-level resource definitions High-level network constructs Learning Curve Steeper Gentler Speed Faster Slower Flexibility Highly flexible Opinionated patterns Best For Complex custom logic Standard network patterns"},{"location":"lab-guides/lab2-terraform-nac/nac-setup/#lab-2-objectives","title":"Lab 2 Objectives","text":"<p>In this lab, you will:</p> <ol> <li>Set up the NAC Terraform environment</li> <li>Create YAML configuration for RoCEv2 QoS</li> <li>Deploy using the NAC provider</li> <li>Compare with Lab 1's approach</li> </ol>"},{"location":"lab-guides/lab2-terraform-nac/nac-setup/#steps","title":"Steps","text":"<p>Navigate back to /opt/, then create a nac directory. This is where we will utilize a NAC Comparison.</p> <pre><code>cd /opt/\nmkdir nac\ncd nac\n</code></pre> <p>Clone the Netascode ACI simple example repository:</p> <pre><code>git clone https://github.com/netascode/nac-aci-simple-example.git\n</code></pre> <p>(Output will show cloning progress.)</p> <p>Navigate into the cloned directory:</p> <pre><code>cd nac-aci-simple-example/\n</code></pre>"},{"location":"lab-guides/lab2-terraform-nac/nac-setup/#next-steps","title":"Next Steps","text":"<p>Proceed to Root main.tf to understand the NAC root module structure.</p>"},{"location":"lab-guides/lab2-terraform-nac/root-main-tf/","title":"Understanding the Root main.tf","text":""},{"location":"lab-guides/lab2-terraform-nac/root-main-tf/#overview","title":"Overview","text":"<p>This main.tf file is the entry point for Terraform in the original NAC environment. It connects to two APICs, loads a Netascode ACI module from the Terraform Registry, applies QoS-related configuration using YAML data, and wires in a reset script to clean the lab on destroy. Edit the existing main.tf file by entering \u2018vi main.tf\u2019 from this directory</p> <pre><code>vi main.tf\n</code></pre> <p>Completely overwrite the main.tf file that is directly underneath the nac-aci-simple-example folder with the content below to paste. </p> <p>Vi Editor Tips</p> <p>Press dd to remove all text line for line, or hold d down to remove all lines quickly</p> <p>Vi Editor Tips</p> <p>Press i to insert text, then copy and paste all the content below.</p>"},{"location":"lab-guides/lab2-terraform-nac/root-main-tf/#create-maintf","title":"Create <code>main.tf</code>","text":"<pre><code># This block tells Terraform to use the CiscoDevNet aci provider. Any configuration that references provider \"aci\" depends on this plugin, ensuring Terraform downloads and uses the correct provider when interacting with the APIC.\n\nterraform {\n  required_providers {\n    aci = {\n      source = \"CiscoDevNet/aci\"\n    }\n  }\n}\n\n# Two aci provider blocks are defined\u2014one for each APIC cluster. Each connects to a different fabric using its own URL and credentials, allowing both ACI fabrics to be managed within a single Terraform project.\n\nprovider \"aci\" {\n  alias    = \"apic1\"\n  username = \"admin\"\n  password = \"C1sco12345\"\n  url      = \"https://198.18.133.200\"\n}\n\nprovider \"aci\" {\n  alias    = \"apic2\"\n  username = \"admin\"\n  password = \"C1sco12345\"\n  url      = \"https://198.18.132.200\"\n}\n\n# Each module block calls the Netascode ACI module, targets a specific APIC, and reads the QoS configuration from the YAML files in the data directory. Access policies are enabled, allowing the same YAML-driven configuration to be applied consistently to both fabrics.\n\n\nmodule \"apic1_qos\" {\n  source  = \"netascode/nac-aci/aci\"\n  version = \"1.0.1\"\n\n  providers = {\n    aci = aci.apic1\n  }\n\n  yaml_directories = [\"data\"]\n\n  manage_access_policies    = true\n  manage_fabric_policies    = false\n  manage_pod_policies       = false\n  manage_node_policies      = false\n  manage_interface_policies = false\n  manage_tenants            = false\n}\n\nmodule \"apic2_qos\" {\n  source  = \"netascode/nac-aci/aci\"\n  version = \"1.0.1\"\n\n  providers = {\n    aci = aci.apic2\n  }\n\n  yaml_directories = [\"data\"]\n\n  manage_access_policies    = true\n  manage_fabric_policies    = false\n  manage_pod_policies       = false\n  manage_node_policies      = false\n  manage_interface_policies = false\n  manage_tenants            = false\n}\n\n# Resetting QoS on Destroy (Calling the Script): Two null_resource blocks define cleanup actions that run only during terraform destroy. They execute the reset_qos.sh script from the project\u2019s scripts folder with different APIC URLs, ensuring QoS is reset on both fabrics:\n\nresource \"null_resource\" \"reset_qos_apic1a\" {\n  provisioner \"local-exec\" {\n    when    = destroy\n    command = \"bash ${path.root}/scripts/reset_qos.sh https://apic1-a.corp.pseudoco.com\"\n  }\n}\n\nresource \"null_resource\" \"reset_qos_apic1b\" {\n  provisioner \"local-exec\" {\n    when    = destroy\n    command = \"bash ${path.root}/scripts/reset_qos.sh https://apic1-b.corp.pseudoco.com\"\n  }\n}\n</code></pre>"},{"location":"lab-guides/lab2-terraform-nac/root-main-tf/#save-the-file","title":"Save the File","text":"<p>Save the file by pressing Esc, then typing :wq!</p>"},{"location":"lab-guides/lab2-terraform-nac/root-main-tf/#verify-the-file","title":"Verify the File","text":"<p>Once outside the vi editor, the file can be verified by typing:</p> <pre><code>cat main.tf\n</code></pre>"},{"location":"lab-guides/lab2-terraform-nac/root-main-tf/#next-steps","title":"Next Steps","text":"<p>Proceed to YAML File to create your NAC YAML configuration.</p>"},{"location":"lab-guides/lab2-terraform-nac/script-integration/","title":"NAC Script Integration","text":""},{"location":"lab-guides/lab2-terraform-nac/script-integration/#overview","title":"Overview","text":"<p>This script provides a simple, direct way to reset the QoS configuration on an APIC cluster using raw REST API calls via curl. It is executed from Terraform as part of the null_resource provisioners during terraform destroy. This is the same as the previous Terraform exercise.</p>"},{"location":"lab-guides/lab2-terraform-nac/script-integration/#create-reset-script","title":"Create Reset Script","text":"<p>Navigate back to the nac-aci-simple-example directory, create, then go into into the scripts directory:</p> <p><pre><code>cd ..\nmkdir scripts\ncd scripts\n</code></pre> Create the reset_qos.sh script:</p> <pre><code>vi reset_qos.sh\n</code></pre> <p>Vi Editor Tips</p> <p>Press i to insert text, then copy and paste all the content below.</p> <pre><code>#!/bin/bash\n\nAPIC_URL=\"$1\"\nUSERNAME=\"admin\"\nPASSWORD=\"C1sco12345\"\n\necho \"Resetting QoS configuration on $APIC_URL...\"\n\n# Sends a login request to the APIC and saves the authentication cookie to apic-cookie.txt for later API calls.\n\ncurl -sk -X POST \"$APIC_URL/api/aaaLogin.json\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"aaaUser\\\":{\\\"attributes\\\":{\\\"name\\\":\\\"$USERNAME\\\",\\\"pwd\\\":\\\"$PASSWORD\\\"}}}\" \\\n  -c apic-cookie.txt\n\n# Sends an XML payload to the APIC to reset the QoS class configuration back to its default settings\n\ncurl -sk -X POST \"$APIC_URL/api/node/mo/uni.xml\" \\\n  -H \"Content-Type: application/xml\" \\\n  -d '&lt;qosClass admin=\"enabled\" dn=\"uni/infra/qosinst-default/class-level2\" prio=\"level2\"&gt;\n         &lt;qosCong algo=\"tail-drop\" ecn=\"disabled\"/&gt;\n         &lt;qosPfcPol name=\"default\" adminSt=\"no\" noDropCos=\"\" enableScope=\"fabric\"/&gt;\n         &lt;qosSched bw=\"20\"/&gt;\n       &lt;/qosClass&gt;' \\\n  -b apic-cookie.txt\n\necho \"Reset complete.\"\n</code></pre>"},{"location":"lab-guides/lab2-terraform-nac/script-integration/#save-the-file","title":"Save the File","text":"<p>Save the file by pressing Esc, then typing :wq!</p>"},{"location":"lab-guides/lab2-terraform-nac/script-integration/#verify-the-file","title":"Verify the File","text":"<p>Once outside the vi editor, the file can be verified by typing:</p> <pre><code>cat reset_qos.sh\n</code></pre>"},{"location":"lab-guides/lab2-terraform-nac/script-integration/#next-steps","title":"Next Steps","text":"<p>Proceed to Apply Terraform to deploy the NAC configuration to both ACI fabrics.</p>"},{"location":"lab-guides/lab2-terraform-nac/understanding-yaml/","title":"Understanding qos_rocev2.nac.yaml","text":""},{"location":"lab-guides/lab2-terraform-nac/understanding-yaml/#overview","title":"Overview","text":"<p>This section explains each component of the NAC YAML configuration and how it implements RoCEv2 QoS on ACI.</p>"},{"location":"lab-guides/lab2-terraform-nac/understanding-yaml/#configuration-breakdown","title":"Configuration Breakdown","text":"<p>This YAML file defines the RoCEv2 QoS policy in a declarative way for the Netascode nac-aci Terraform module. Instead of writing all the ACI objects directly in Terraform, the intent in YAML is described, and the Netascode module translates it into the appropriate ACI MOs (such as qosClass, qosCong, and qosPfcPol).</p> <p>Top-Level Structure The structure apic: access_policies: qos: qos_classes: indicates that this YAML defines QoS-related access policies for the APIC, specifically a list of QoS classes.</p> <p>Defining the RoCEv2 QoS Class This single YAML block describes the QoS behavior for class level: 2, which maps to qosClass level2 in ACI.</p> <p>level: 2 Sets the QoS class level, corresponding to uni/infra/qosinst-default/class-level2 in ACI. This is the class you use for RoCEv2 / no-drop traffic.</p> <p>congestion_algorithm: wred Selects WRED for congestion management, mapping to algo = \"wred\" in ACI. Combined with thresholds below, it defines how congestion is detected and when early drops/marks occur:</p> <ul> <li>wred_min_threshold: 40 \u2192 start threshold (e.g. 40%)</li> <li>wred_max_threshold: 60 \u2192 max threshold (e.g. 60%)</li> <li>wred_probability: 0 \u2192 drop/mark probability at those thresholds</li> </ul> <p>ecn: true Enables Explicit Congestion Notification, mapping to ecn = \"enabled\". This means congestion can be signalled via ECN marks rather than relying only on packet drops.</p> <p>forward_non_ecn: true Enables the forwarding of traffic that has not been marked with Explicit Congestion Notification (ECN). This maps to forwardNonEcn = \"enabled\" within the qosCong MO in ACI.</p> <p>bandwidth_percent: 60 Allocates a specific percentage of the available bandwidth to this QoS class. This maps to bw = \"60\" within the qosSched MO in ACI, ensuring a guaranteed bandwidth share for this traffic.</p> <p>pfc_state: true Turns Priority Flow Control (PFC) on, mapping to adminSt = \"yes\" for qosPfcPol. PFC ensures that traffic in the selected CoS can be treated as no-drop (crucial for RoCEv2).</p> <p>no_drop_cos: cos3 Specifies cos3 as the no-drop Class of Service, mapping to noDropCos = \"cos3\". This aligns nicely with the Terraform variable you use elsewhere (var.cos), and makes it explicit in human-readable YAML.</p> <p>pfc_scope: fabric Defines the scope of the PFC policy as fabric-wide.</p> <p>How This YAML Relates to the Terraform: In the main.tf, yaml_directories = [\"data\"] tells the Netascode module to read all .nac.yaml files in the data/ directory, including qos_rocev2.nac.yaml. The module then converts this YAML intent into the appropriate ACI MOs for both APIC1 and APIC2.</p>"},{"location":"lab-guides/lab2-terraform-nac/understanding-yaml/#next-steps","title":"Next Steps","text":"<p>Proceed to Script Integration to create helper scripts for the NAC deployment.</p>"},{"location":"lab-guides/lab2-terraform-nac/yaml-file/","title":"NAC YAML File - qos_rocev2.nac.yaml","text":""},{"location":"lab-guides/lab2-terraform-nac/yaml-file/#overview","title":"Overview","text":"<p>The NAC YAML file defines your network configuration in a declarative, human-readable format. This file describes the RoCEv2 QoS policies without requiring Terraform/HCL knowledge.</p>"},{"location":"lab-guides/lab2-terraform-nac/yaml-file/#create-the-yaml-configuration","title":"Create the YAML Configuration","text":"<p>Navigate into the data directory and create the \u2018qos_rocev2.nac.yaml\u2019 file</p> <pre><code>cd data\nvi qos_rocev2.nac.yaml\n</code></pre> <p>Vi Editor Tips</p> <p>Press i to insert text, then copy and paste all the content below.</p> <p>Add the following content:</p> <pre><code>---\napic:\n  access_policies:\n    qos:\n      qos_classes:\n        - level: 2\n          congestion_algorithm: wred\n          wred_min_threshold: 40\n          wred_max_threshold: 60\n          wred_probability: 0\n          ecn: true\n          forward_non_ecn: true\n          bandwidth_percent: 60\n          pfc_state: true\n          no_drop_cos: cos3\n          pfc_scope: fabric\n</code></pre>"},{"location":"lab-guides/lab2-terraform-nac/yaml-file/#save-the-file","title":"Save the File","text":"<p>Save the file by pressing Esc, then typing :wq!</p>"},{"location":"lab-guides/lab2-terraform-nac/yaml-file/#verify-the-file","title":"Verify the File","text":"<p>Once outside the vi editor, the file can be verified by typing:</p> <pre><code>cat qos_rocev2.nac.yaml\n</code></pre>"},{"location":"lab-guides/lab2-terraform-nac/yaml-file/#next-steps","title":"Next Steps","text":"<p>Proceed to Understanding YAML for a detailed explanation of each configuration section.</p>"},{"location":"lab-guides/lab3-python/execute-script/","title":"Executing the Python Script","text":""},{"location":"lab-guides/lab3-python/execute-script/#overview","title":"Overview","text":"<p>In this final section, you will create and execute a Python script that deploys RoCEv2 QoS policies to both ACI fabrics using the REST API.</p>"},{"location":"lab-guides/lab3-python/execute-script/#login-to-both-apics","title":"Login to Both APICs","text":"<p>Login to each APIC in the same way as has been previously done via the Terraform exercises to validate this script working in the exact same way, with each screen showing the Level 2 QoS configuration:</p> <p></p>"},{"location":"lab-guides/lab3-python/execute-script/#executing-the-python-script_1","title":"Executing the Python Script","text":"<ul> <li> <p>Open Command Prompt again from the Taskbar, change the directory to the Python Folder</p> </li> <li> <p>Run the Python script to apply the configuration: python rocev2_qos.py apply</p> </li> </ul> <pre><code>python rocev2_qos.py apply\n</code></pre> <p></p> <ul> <li>Observe the changes in the APIC GUI.</li> <li>Run the Python script to reset the configuration: python rocev2_qos.py destroy</li> </ul> <pre><code>python rocev2_qos.py apply\n</code></pre> <ul> <li>Observe the APIC GUI reverting to its normal state.</li> </ul>"},{"location":"lab-guides/lab3-python/execute-script/#lab-3-complete","title":"Lab 3 Complete!","text":"<p>Congratulations! You have successfully:</p> <ul> <li>\u2705 Installed Python and ACI SDK</li> <li>\u2705 Created authentication module</li> <li>\u2705 Deployed RoCEv2 QoS via Python</li> <li>\u2705 Verified configuration in APIC GUI</li> </ul>"},{"location":"lab-guides/lab3-python/execute-script/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Python provides maximum flexibility - Full programming capabilities</li> <li>REST API direct access - Understand exactly what's happening</li> <li>Requires more code - But offers more control</li> <li>Great for integration - Easy to connect with other systems</li> </ol>"},{"location":"lab-guides/lab3-python/execute-script/#next-steps","title":"Next Steps","text":"<p>Ready for the next approach? Proceed to Lab 4: Bruno API to explore API automation using the Bruno GUI client.</p>"},{"location":"lab-guides/lab3-python/python-overview/","title":"Python Overview","text":"<p>Python is widely used for network and infrastructure automation because it is simple, readable, and easy to learn. Its clear syntax lets engineers focus on automation logic rather than language complexity, making it well suited for fast-paced lab environments.</p> <p>In automation workflows, Python often complements declarative tools like Terraform and Ansible. It is commonly used for tasks such as validation, generating inputs, verification, and cleanup\u2014areas that are harder to express using declarative models alone.</p> <p>Python\u2019s rich ecosystem of libraries makes it easy to interact directly with APIs, controllers, and platforms such as Cisco ACI and Nexus Dashboard. This flexibility and broad support make Python a core tool in real-world network automation:</p> <ul> <li>Cisco ACI Python SDK Documentation</li> <li>Devnet Python ACI Examples</li> <li>Github Python ACI Examples)</li> </ul>"},{"location":"lab-guides/lab3-python/python-overview/#why-python-for-aci-automation","title":"Why Python for ACI Automation?","text":"<ul> <li>Flexibility - Full programming capabilities for complex logic</li> <li>Integration - Easy to integrate with other systems and tools</li> <li>Cisco Support - Official Cobra SDK from Cisco</li> <li>Scripting - Quick one-off tasks and automation</li> <li>Community - Large ecosystem of libraries and examples</li> </ul>"},{"location":"lab-guides/lab3-python/python-overview/#next-steps","title":"Next Steps","text":"<p>Proceed to Verify Python</p>"},{"location":"lab-guides/lab3-python/verify-python/","title":"Verify Python &amp; Install Dependencies","text":""},{"location":"lab-guides/lab3-python/verify-python/#step-1-verify-python-installation","title":"Step 1: Verify Python Installation","text":"<p>Check Python version:</p> <p>Verify Python version on Windows Machine: Open Command Prompt from the Task Bar and type python \u2013version:</p> <pre><code>python --version\n</code></pre> <p></p> <p>Install the requests library (if not already installed): pip install requests</p> <pre><code>pip install requests\n</code></pre> <p></p> <p>Locate the Python script: Open Explorer from the Taskbar, navigate to the Demouser folder, then Python folder, and open the \u2018rocev2qos.py\u2019 Python File in Visual Studio Code (or Notepad++) to view its content:</p> <p></p> <p>The Python Code can now be viewed including # comments describing the script. Please refer to Appendix B to review the Python Script at greater detail:</p> <p></p>"},{"location":"lab-guides/lab3-python/verify-python/#next-steps","title":"Next Steps","text":"<p>Proceed to Execute Script to create a Python script that applies the QoS policies to both APIC controllers.</p>"},{"location":"lab-guides/lab4-bruno/apply-qos-policy/","title":"Apply QoS Policy","text":""},{"location":"lab-guides/lab4-bruno/apply-qos-policy/#overview","title":"Overview","text":"<p>In this final step of Lab 4, you'll use Bruno to create the complete RoCEv2 QoS configuration on both ACI fabrics through REST API calls.</p>"},{"location":"lab-guides/lab4-bruno/apply-qos-policy/#steps","title":"Steps","text":"<ul> <li>Select the 1<sup>st</sup> POST Command</li> <li>Click on the Arrow on the right-hand side of the window to apply the POST Command. You should receive a 200 OK, indicating successful login:</li> </ul> <ul> <li> <p>Select the 2<sup>nd</sup> POST Command: Apply the QoS Config. Have the APIC GUI in the background to verify that QoS has been applied successfully.</p> </li> <li> <p>Select the 3<sup>rd</sup> POST Command: Reset the QoS Config back to its original Best Effort State.</p> </li> <li> <p>Optional: Modify the base_url environment to point to the second APIC (e.g., https://apic1-b.corp.pseudoco.com). Click Save then Activate.</p> </li> </ul> <p></p> <ul> <li> <p>Repeat the above steps with the POST Commands and verify successful application to the second APIC via the GUI.</p> </li> <li> <p>Optional: Open the RoCEv2 ACI - Full Postman Collection.postman_collection file in Visual Studio Code to view its structure:</p> </li> </ul> <p></p> <ul> <li>Notice how the script separates sections for logging in, applying QoS, and removing QoS:</li> </ul> <p></p>"},{"location":"lab-guides/lab4-bruno/apply-qos-policy/#lab-4-complete","title":"Lab 4 Complete!","text":"<p>Congratulations! You have successfully:</p> <ul> <li>\u2705 Imported Bruno collection</li> <li>\u2705 Configured environments</li> <li>\u2705 Authenticated to both APICsS</li> <li>\u2705 Created RoCEv2 QoS via REST API</li> <li>\u2705 Verified in APIC GUI</li> </ul>"},{"location":"lab-guides/lab4-bruno/apply-qos-policy/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Bruno provides visual API interaction - Great for learning and testing</li> <li>REST API is the foundation - All tools eventually use the REST API</li> <li>Collections are reusable - Share with team, version control</li> <li>Environments enable flexibility - Easy testing across multiple fabrics</li> </ol>"},{"location":"lab-guides/lab4-bruno/apply-qos-policy/#next-steps","title":"Next Steps","text":"<p>Proceed to Lab 5: Ansible Playbooks for the final lab!</p>"},{"location":"lab-guides/lab4-bruno/bruno-overview/","title":"Bruno Overview","text":"<p>Bruno is a lightweight, open-source REST client designed for automation and API workflows. It stores API requests as plain text files (JSON or YAML), making them easy to version-control and share alongside Terraform, Ansible, or Python code. This makes Bruno well suited for exploring and validating APIs such as the Cisco ACI APIC in a clear and repeatable way.</p> <p>In practice, Bruno is used to prototype and test API calls before automating them. Engineers can quickly verify requests and responses, switch between environments, and confirm behaviour across multiple fabrics. This makes Bruno a useful bridge between manual API exploration and fully automated IaC workflows.</p>"},{"location":"lab-guides/lab4-bruno/bruno-overview/#what-is-bruno","title":"What is Bruno?","text":"<p>Bruno is a modern API client that:</p> <ul> <li>Stores collections as files - Git-friendly, text-based storage</li> <li>Supports environments - Easy switching between dev/test/prod</li> <li>Provides scripting - Pre-request and post-response scripts</li> <li>Works offline - No cloud dependency</li> <li>Open Source - Free and community-driven</li> </ul>"},{"location":"lab-guides/lab4-bruno/bruno-overview/#why-use-bruno-for-aci","title":"Why Use Bruno for ACI?","text":"<ul> <li>Visual Interface - See API requests and responses clearly</li> <li>Learning Tool - Understand ACI REST API structure</li> <li>Testing - Quickly test API calls before coding</li> <li>Documentation - Self-documenting API collections</li> <li>Sharing - Export collections for team collaboration</li> </ul> <p>This section covers using Bruno to interact with the APIC API for QoS configuration.</p>"},{"location":"lab-guides/lab4-bruno/bruno-overview/#next-steps","title":"Next Steps","text":"<p>Proceed to Import Collection to deploy RoCEv2 QoS configuration using the Bruno API client.</p>"},{"location":"lab-guides/lab4-bruno/configure-environment/","title":"Lab 4.2: Configure Environment","text":""},{"location":"lab-guides/lab4-bruno/configure-environment/#overview","title":"Overview","text":"<p>Bruno environments allow you to store variables like URLs, credentials, and tokens. This enables easy switching between different APIC controllers.</p>"},{"location":"lab-guides/lab4-bruno/configure-environment/#view-environments","title":"View Environments","text":"<ul> <li>Click No environments in the top right-hand side of the window, then select Create:</li> </ul> <ul> <li>Call it 'base_url'</li> </ul> <ul> <li>Select 'Enabled', then \u2018base_url\u2019 again as the Name, with the Value of \u2018https://apic1-a.corp.pseudoco.com\u2019. Click 'Save' then 'Activate':</li> </ul>"},{"location":"lab-guides/lab4-bruno/configure-environment/#next-steps","title":"Next Steps","text":"<p>Proceed to Apply QoS Policy to execute the final steps.</p>"},{"location":"lab-guides/lab4-bruno/import-collection/","title":"Import Collection","text":""},{"location":"lab-guides/lab4-bruno/import-collection/#step-1-launch-bruno","title":"Step 1: Launch Bruno","text":"<ul> <li>Open Bruno from the Desktop or Taskbar of the Windows machine</li> <li>Select Import Collection.</li> </ul>"},{"location":"lab-guides/lab4-bruno/import-collection/#step-2-locate-the-collection","title":"Step 2: Locate the Collection","text":"<ul> <li>Select the RoCEv2 ACI - Full Postman Collection.postman_collection file:</li> </ul> <ul> <li>Select the RoCEv2 ACI - Full Postman Collection folder that appears:</li> </ul> <ul> <li>Click Import</li> </ul> <ul> <li>The Collection is on the left-hand side of the screen. Click it, and a pop-up will appear. Choose Safe Mode:</li> </ul>"},{"location":"lab-guides/lab4-bruno/import-collection/#next-steps","title":"Next Steps","text":"<p>Proceed to Configure Environment to set up the APIC connection details.</p>"},{"location":"lab-guides/lab5-ansible/ansible-overview/","title":"Lab 5: Ansible Playbooks Automation","text":""},{"location":"lab-guides/lab5-ansible/ansible-overview/#introduction","title":"Introduction","text":"<p>Ansible is an agentless automation tool used for configuration, orchestration, and operational tasks across infrastructure and networks. It uses human-readable YAML playbooks and connects over standard protocols such as SSH or HTTPS, avoiding the need for agents. Ansible is particularly strong for day-0 and day-2 operations where execution order, conditions, and error handling matter.</p> <p>Compared to Terraform, Ansible provides more procedural control. While Terraform focuses on declarative provisioning and state management, Ansible allows engineers to define step-by-step workflows, making it well suited to brownfield or operationally complex environments. The two tools are often used together, with Ansible complementing Terraform's lifecycle management:</p>"},{"location":"lab-guides/lab5-ansible/ansible-overview/#terraform-vs-ansible-comparison","title":"Terraform vs Ansible Comparison","text":"Feature Terraform Ansible Automation Style Declarative Procedural Primary Focus Provisioning &amp; state Configuration &amp; operations State Management Built-in state file No persistent state Execution Model Desired end state Step-by-step tasks Strengths Repeatability, drift control Sequencing, logic, remediation Best Fit Day-0 provisioning Day-1 / Day-2 operations"},{"location":"lab-guides/lab5-ansible/ansible-overview/#ansible-galaxy-and-aci-support","title":"Ansible Galaxy and ACI Support","text":"<p>Ansible Galaxy is the ecosystem for sharing reusable automation content such as roles and collections. Vendors like Cisco publish supported collections (for example, <code>cisco.aci</code>), allowing teams to automate platforms such as ACI quickly and consistently without building everything from scratch.</p>"},{"location":"lab-guides/lab5-ansible/ansible-overview/#useful-resources","title":"Useful Resources","text":"<ul> <li>Ansible ACI Community Documentation</li> <li>ACI Ansible Plugins Collection</li> <li>ACI Ansible Github Repository</li> <li>Devnet Ansible ACI Lab</li> <li>Ansible Galaxy ACI Documentation</li> </ul>"},{"location":"lab-guides/lab5-ansible/ansible-overview/#what-youll-learn","title":"What You'll Learn","text":"<p>This section details the use of Ansible playbooks to automate the application and resetting of RoCEv2 QoS configurations across multiple APIC fabrics.</p> <p>In this lab, you will:</p> <ul> <li>Set up an Ansible directory structure</li> <li>Create inventory files for multiple APIC controllers</li> <li>Define variables for APIC credentials and connection details</li> <li>Write playbooks to apply RoCEv2 QoS configuration</li> <li>Write playbooks to reset QoS to default settings</li> <li>Execute playbooks across multiple APIC fabrics simultaneously</li> </ul> <p>Proceed to Setup Directory Structure.</p>"},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/","title":"Create Apply QoS Playbook","text":""},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/#about-this-playbook","title":"About This Playbook","text":"<p>The <code>rocev2_qos.yml</code> playbook applies RoCEv2 QoS configuration to the APIC controllers. It configures:</p> <ul> <li>WRED (Weighted Random Early Detection) congestion control</li> <li>ECN (Explicit Congestion Notification) enabled</li> <li>PFC (Priority Flow Control) on CoS 3</li> <li>60% bandwidth allocation for Level 2 traffic</li> </ul>"},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/#navigate-to-playbooks-directory","title":"Navigate to Playbooks Directory","text":"<p>Navigate to the playbooks directory:</p> <pre><code>cd ..\ncd playbooks/\n</code></pre>"},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/#create-the-playbook","title":"Create the Playbook","text":"<p>Create the <code>rocev2_qos.yml</code> playbook by executing <code>vi rocev2_qos.yml</code> and pasting the following content:</p> <pre><code>vi rocev2_qos.yml\n</code></pre> <p>Vi Editor Tips</p> <p>Press i to insert text, then copy and paste all the content below.</p>"},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/#playbook-content","title":"Playbook Content","text":"<pre><code>---\n- name: Apply RoCEv2 QoS Config to ACI\n  hosts: apic\n  gather_facts: no\n\n  tasks:\n    - name: Login to APIC and retrieve cookie\n      uri:\n        url: \"{{ apic_url }}/api/aaaLogin.json\"\n        method: POST\n        body_format: json\n        headers:\n          Content-Type: application/json\n        body:\n          aaaUser:\n            attributes:\n              name: \"{{ apic_username }}\"\n              pwd: \"{{ apic_password }}\"\n        return_content: yes\n        status_code: 200\n        validate_certs: no\n      register: login_response\n\n    - name: Extract APIC auth cookie\n      set_fact:\n        apic_cookie: \"{{ login_response.cookies['APIC-cookie'] }}\"\n\n    - name: Configure QoS Class Level2 for RoCEv2\n      uri:\n        url: \"{{ apic_url }}/api/node/mo/uni.xml\"\n        method: POST\n        headers:\n          Content-Type: application/xml\n          Cookie: \"APIC-cookie={{ apic_cookie }}\"\n        body: |\n          &lt;qosClass admin=\"enabled\" dn=\"uni/infra/qosinst-default/class-level2\" prio=\"level2\"&gt;\n            &lt;qosCong algo=\"wred\" wredMinThreshold=\"40\" wredMaxThreshold=\"60\" wredProbability=\"0\" ecn=\"enabled\" forwardNonEcn=\"enabled\"/&gt;\n            &lt;qosPfcPol name=\"default\" noDropCos=\"cos3\" adminSt=\"yes\" enableScope=\"fabric\"/&gt;\n            &lt;qosSched bw=\"60\"/&gt;\n          &lt;/qosClass&gt;\n        body_format: raw\n        status_code: 200\n        validate_certs: no\n</code></pre>"},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/#save-the-file","title":"Save the File","text":"<p>Save the file by pressing Esc, then typing :wq!</p>"},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/#verify-the-file","title":"Verify the File","text":"<p>Once outside the vi editor, the file can be verified by typing:</p> <pre><code>cat rocev2_qos.yml\n</code></pre>"},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/#understanding-the-playbook","title":"Understanding the Playbook","text":""},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/#play-definition","title":"Play Definition","text":"<p><pre><code>- name: Apply RoCEv2 QoS Config to ACI\n  hosts: apic\n  gather_facts: no\n</code></pre> - Runs against all hosts in the <code>[apic]</code> group - Disables fact gathering for faster execution</p>"},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/#task-1-authentication","title":"Task 1: Authentication","text":"<p><pre><code>- name: Login to APIC and retrieve cookie\n  uri:\n    url: \"{{ apic_url }}/api/aaaLogin.json\"\n    ...\n  register: login_response\n</code></pre> - Authenticates to the APIC using REST API - Stores the response (including authentication cookie) in <code>login_response</code></p>"},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/#task-2-extract-cookie","title":"Task 2: Extract Cookie","text":"<p><pre><code>- name: Extract APIC auth cookie\n  set_fact:\n    apic_cookie: \"{{ login_response.cookies['APIC-cookie'] }}\"\n</code></pre> - Extracts the authentication cookie from the login response - Stores it as a fact for use in subsequent tasks</p>"},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/#task-3-configure-qos","title":"Task 3: Configure QoS","text":"<p><pre><code>- name: Configure QoS Class Level2 for RoCEv2\n  uri:\n    url: \"{{ apic_url }}/api/node/mo/uni.xml\"\n    ...\n    body: |\n      &lt;qosClass admin=\"enabled\" dn=\"uni/infra/qosinst-default/class-level2\" prio=\"level2\"&gt;\n        ...\n      &lt;/qosClass&gt;\n</code></pre> - Sends XML payload to configure QoS settings - Uses the authentication cookie from the previous task - Configures WRED, ECN, PFC, and bandwidth allocation</p>"},{"location":"lab-guides/lab5-ansible/apply-qos-playbook/#qos-configuration-details","title":"QoS Configuration Details","text":"Setting Value Purpose Algorithm WRED Weighted Random Early Detection for congestion WRED Min 40% Minimum threshold before packet dropping starts WRED Max 60% Maximum threshold for full dropping ECN Enabled Explicit Congestion Notification PFC CoS CoS 3 Priority Flow Control on Class of Service 3 Bandwidth 60% Guaranteed bandwidth for Level 2 traffic <p>Proceed to Reset QoS Playbook.</p>"},{"location":"lab-guides/lab5-ansible/group-vars-file/","title":"Create group_vars/apic.yml File","text":""},{"location":"lab-guides/lab5-ansible/group-vars-file/#about-group-variables","title":"About Group Variables","text":"<p>The <code>group_vars</code> directory contains variable files that are automatically loaded for specific host groups. By creating <code>apic.yml</code>, these variables will be available to all hosts in the <code>[apic]</code> group.</p>"},{"location":"lab-guides/lab5-ansible/group-vars-file/#navigate-to-group_vars","title":"Navigate to group_vars","text":"<p>Navigate to the group_vars directory:</p> <pre><code>cd group_vars/\n</code></pre>"},{"location":"lab-guides/lab5-ansible/group-vars-file/#create-the-apicyml-file","title":"Create the apic.yml File","text":"<p>Create the <code>apic.yml</code> file by executing <code>vi apic.yml</code> and pasting the following content:</p> <pre><code>vi apic.yml\n</code></pre> <p>Vi Editor Tips</p> <p>Press i to insert text, then copy and paste all the content below.</p>"},{"location":"lab-guides/lab5-ansible/group-vars-file/#group-variables-content","title":"Group Variables Content","text":"<pre><code>apic_username: admin\napic_password: C1sco12345\napic_url: \"https://{{ inventory_hostname }}\"\n</code></pre>"},{"location":"lab-guides/lab5-ansible/group-vars-file/#save-the-file","title":"Save the File","text":"<p>Save the file by pressing Esc, then typing :wq!</p>"},{"location":"lab-guides/lab5-ansible/group-vars-file/#verify-the-file","title":"Verify the File","text":"<p>Once outside the vi editor, the file can be verified by typing:</p> <pre><code>cat apic.yml\n</code></pre>"},{"location":"lab-guides/lab5-ansible/group-vars-file/#understanding-the-variables","title":"Understanding the Variables","text":"<ul> <li>apic_username - Username for APIC authentication</li> <li>apic_password - Password for APIC authentication  </li> <li>apic_url - Dynamically constructed URL using the inventory hostname</li> </ul> <p>Jinja2 Templating</p> <p>The <code>{{ inventory_hostname }}</code> syntax is Jinja2 templating. Ansible will automatically replace this with the actual hostname from the inventory file for each host the playbook runs against.</p> <p>This approach allows us to use a single variable definition that works for multiple APIC controllers without hardcoding specific URLs.</p> <p>Proceed to Apply QoS Playbook.</p>"},{"location":"lab-guides/lab5-ansible/inventory-file/","title":"Create inventory.ini File","text":""},{"location":"lab-guides/lab5-ansible/inventory-file/#about-inventory-files","title":"About Inventory Files","text":"<p>The Ansible inventory file defines which hosts (APIC controllers in our case) the playbooks will run against. It also allows you to define groups of hosts and set variables that apply to those groups.</p>"},{"location":"lab-guides/lab5-ansible/inventory-file/#create-the-inventory-file","title":"Create the Inventory File","text":"<p>Create the <code>inventory.ini</code> file in <code>/opt/ansible</code> by executing <code>vi inventory.ini</code> and pasting the following content:</p> <pre><code>vi inventory.ini\n</code></pre> <p>Vi Editor Tips</p> <p>Press i to insert text, then copy and paste all the content below in one go from the beginning to the end.</p>"},{"location":"lab-guides/lab5-ansible/inventory-file/#inventory-file-content","title":"Inventory File Content","text":"<pre><code>[apic]\napic1-a.corp.pseudoco.com\napic1-b.corp.pseudoco.com\n\n[apic:vars]\nansible_connection=local\napic_username=admin\napic_password=C1sco12345\n</code></pre> <p>Credentials in Inventory</p> <p>This lab uses hardcoded credentials for simplicity. In production environments, use Ansible Vault or external secret management systems to protect sensitive credentials.</p>"},{"location":"lab-guides/lab5-ansible/inventory-file/#save-the-file","title":"Save the File","text":"<p>Save the file by pressing Esc, then typing :wq!</p>"},{"location":"lab-guides/lab5-ansible/inventory-file/#verify-the-file","title":"Verify the File","text":"<p>Once outside the vi editor, the script can be verified by typing:</p> <pre><code>cat inventory.ini\n</code></pre>"},{"location":"lab-guides/lab5-ansible/inventory-file/#understanding-the-inventory","title":"Understanding the Inventory","text":"<ul> <li>[apic] - Defines a host group named \"apic\"</li> <li>apic1-a.corp.pseudoco.com and apic1-b.corp.pseudoco.com - The two APIC controllers</li> <li>[apic:vars] - Variables that apply to all hosts in the \"apic\" group</li> <li>ansible_connection=local - Tells Ansible to run API calls locally rather than SSH</li> <li>apic_username and apic_password - Credentials for APIC authentication</li> </ul> <p>Proceed to Group Variables File.</p>"},{"location":"lab-guides/lab5-ansible/login-apics/","title":"Login to APIC GUIs","text":"<p>Login to each APIC in the same fashion as the previous exercises with each screen showing the Level 2 QoS configuration:</p> <p></p>"},{"location":"lab-guides/lab5-ansible/login-apics/#current-configuration-before-ansible","title":"Current Configuration (Before Ansible)","text":"<p>You should see the default Best Effort configuration:</p> Setting Default Value Bandwidth 20% Algorithm Tail-drop ECN Disabled PFC Admin State No No-drop CoS (empty) <p>Multiple Browser Tabs</p> <p>Keep both APIC GUI tabs open. After running the Ansible playbook, you can refresh these pages to immediately see the configuration changes applied across both fabrics simultaneously.</p>"},{"location":"lab-guides/lab5-ansible/login-apics/#prepare-for-ansible-execution","title":"Prepare for Ansible Execution","text":"<p>With both APIC GUIs open showing the QoS configuration, you're ready to execute the Ansible playbooks and observe the automated changes in real-time.</p> <p>Proceed to Run Playbooks.</p>"},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/","title":"Create Reset QoS Playbook","text":""},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/#about-this-playbook","title":"About This Playbook","text":"<p>The <code>reset_qos.yml</code> playbook resets QoS configuration back to default settings on the APIC controllers. It configures:</p> <ul> <li>Tail-drop congestion control (disables WRED)</li> <li>ECN disabled</li> <li>PFC disabled</li> <li>20% bandwidth allocation for Level 2 traffic (default)</li> </ul> <p>This playbook is useful for cleanup or returning to baseline configuration.</p>"},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/#create-the-playbook","title":"Create the Playbook","text":"<p>Create the <code>reset_qos.yml</code> playbook by executing <code>vi reset_qos.yml</code> and pasting the following content:</p> <pre><code>vi reset_qos.yml\n</code></pre> <p>Vi Editor Tips</p> <p>Press i to insert text, then copy and paste all the content below.</p>"},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/#playbook-content","title":"Playbook Content","text":"<pre><code>---\n- name: Reset RoCEv2 QoS Config to Default\n  hosts: apic\n  gather_facts: no\n  vars_files:\n    - ../group_vars/apic.yml\n\n  tasks:\n    - name: Login to APIC and retrieve cookie\n      uri:\n        url: \"{{ apic_url }}/api/aaaLogin.json\"\n        method: POST\n        headers:\n          Content-Type: application/json\n        body: &gt;\n          {\n            \"aaaUser\": {\n              \"attributes\": {\n                \"name\": \"{{ apic_username }}\",\n                \"pwd\": \"{{ apic_password }}\"\n              }\n            }\n          }\n        body_format: json\n        return_content: yes\n        status_code: 200\n        validate_certs: no\n      register: login_response\n\n    - name: Extract APIC cookie\n      set_fact:\n        apic_cookie: \"{{ login_response.set_cookie }}\"\n\n    - name: Reset QoS Level2 config (Tail-drop, PFC disabled)\n      uri:\n        url: \"{{ apic_url }}/api/node/mo/uni.xml\"\n        method: POST\n        headers:\n          Content-Type: application/xml\n          Cookie: \"{{ apic_cookie }}\"\n        body: |\n          &lt;qosClass admin=\"enabled\" dn=\"uni/infra/qosinst-default/class-level2\" prio=\"level2\"&gt;\n            &lt;qosCong algo=\"tail-drop\" ecn=\"disabled\" forwardNonEcn=\"disabled\"/&gt;\n            &lt;qosPfcPol name=\"default\" adminSt=\"no\" noDropCos=\"\" enableScope=\"fabric\"/&gt;\n            &lt;qosSched bw=\"20\"/&gt;\n          &lt;/qosClass&gt;\n        body_format: raw\n        status_code: 200\n        validate_certs: no\n</code></pre>"},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/#save-the-file","title":"Save the File","text":"<p>Save the file by pressing Esc, then typing :wq!</p>"},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/#verify-the-file","title":"Verify the File","text":"<p>Once outside the vi editor, the file can be verified by typing:</p> <pre><code>cat reset_qos.yml\n</code></pre>"},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/#understanding-the-playbook","title":"Understanding the Playbook","text":""},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/#play-definition","title":"Play Definition","text":"<p><pre><code>- name: Reset RoCEv2 QoS Config to Default\n  hosts: apic\n  gather_facts: no\n  vars_files:\n    - ../group_vars/apic.yml\n</code></pre> - Runs against all hosts in the <code>[apic]</code> group - Explicitly loads the group variables file - Disables fact gathering for faster execution</p>"},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/#task-1-authentication","title":"Task 1: Authentication","text":"<p>Similar to the apply playbook, authenticates to the APIC and retrieves a session cookie.</p>"},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/#task-2-extract-cookie","title":"Task 2: Extract Cookie","text":"<p>Extracts the authentication cookie for use in API calls.</p>"},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/#task-3-reset-qos-configuration","title":"Task 3: Reset QoS Configuration","text":"<p><pre><code>- name: Reset QoS Level2 config (Tail-drop, PFC disabled)\n  uri:\n    ...\n    body: |\n      &lt;qosClass admin=\"enabled\" dn=\"uni/infra/qosinst-default/class-level2\" prio=\"level2\"&gt;\n        &lt;qosCong algo=\"tail-drop\" ecn=\"disabled\" forwardNonEcn=\"disabled\"/&gt;\n        &lt;qosPfcPol name=\"default\" adminSt=\"no\" noDropCos=\"\" enableScope=\"fabric\"/&gt;\n        &lt;qosSched bw=\"20\"/&gt;\n      &lt;/qosClass&gt;\n</code></pre> - Sends XML payload to reset QoS to default settings - Disables advanced features like WRED, ECN, and PFC - Returns bandwidth allocation to 20%</p>"},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/#default-qos-configuration","title":"Default QoS Configuration","text":"Setting Default Value Purpose Algorithm Tail-drop Simple drop when queue is full ECN Disabled No explicit congestion notification PFC Disabled No priority flow control Bandwidth 20% Default bandwidth for Level 2 traffic"},{"location":"lab-guides/lab5-ansible/reset-qos-playbook/#comparison-apply-vs-reset","title":"Comparison: Apply vs Reset","text":"Feature Apply QoS Reset QoS Congestion Control WRED (40-60%) Tail-drop ECN Enabled Disabled PFC Enabled (CoS 3) Disabled Bandwidth 60% 20% Use Case RoCEv2 optimization Return to defaults <p>Proceed to Login to APICs.</p>"},{"location":"lab-guides/lab5-ansible/run-playbooks/","title":"Running Ansible Playbooks","text":""},{"location":"lab-guides/lab5-ansible/run-playbooks/#navigate-to-ansible-directory","title":"Navigate to Ansible Directory","text":"<p>Navigate back to the ansible directory in the Putty session:</p> <pre><code>cd ..\n</code></pre>"},{"location":"lab-guides/lab5-ansible/run-playbooks/#run-the-apply-qos-playbook","title":"Run the Apply QoS Playbook","text":"<p>Run the playbook to apply the QoS configuration:</p> <pre><code>ansible-playbook -i inventory.ini playbooks/rocev2_qos.yml\n</code></pre>"},{"location":"lab-guides/lab5-ansible/run-playbooks/#expected-output","title":"Expected Output","text":"<p>You should see output showing tasks as <code>ok</code> for both APICs:</p> <pre>\nPLAY RECAP *******************************************************************************\napic1-a.corp.pseudoco.com  : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0\napic1-b.corp.pseudoco.com  : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0\n</pre> <p>Playbook Completed</p> <p>All tasks completed successfully on both APIC controllers. The QoS configuration for RoCEv2 has been applied.</p>"},{"location":"lab-guides/lab5-ansible/run-playbooks/#run-the-reset-qos-playbook","title":"Run the Reset QoS Playbook","text":"<p>Run the playbook to reset the QoS configuration back to defaults:</p> <pre><code>ansible-playbook -i inventory.ini playbooks/reset_qos.yml\n</code></pre>"},{"location":"lab-guides/lab5-ansible/run-playbooks/#expected-output_1","title":"Expected Output","text":"<p>You should see output showing tasks as <code>ok</code> for both APICs:</p> <pre>\nPLAY RECAP *******************************************************************************\napic1-a.corp.pseudoco.com  : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0\napic1-b.corp.pseudoco.com  : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0\n</pre> <p>Playbook Completed</p> <p>All tasks completed successfully on both APIC controllers. The QoS configuration has been reset to default values.</p>"},{"location":"lab-guides/lab5-ansible/run-playbooks/#key-observations","title":"Key Observations","text":""},{"location":"lab-guides/lab5-ansible/run-playbooks/#parallel-execution","title":"Parallel Execution","text":"<p>Notice that Ansible executed tasks on both APIC controllers simultaneously. This is one of Ansible's key strengths - parallel execution across multiple hosts.</p>"},{"location":"lab-guides/lab5-ansible/run-playbooks/#idempotency","title":"Idempotency","text":"<p>If you run the same playbook multiple times, Ansible will report the same result. The playbooks are idempotent - they can be safely run multiple times without causing unintended changes.</p>"},{"location":"lab-guides/lab5-ansible/run-playbooks/#speed","title":"Speed","text":"<p>The entire configuration change across both fabrics completed in seconds. This demonstrates the power of automation compared to manual GUI configuration.</p>"},{"location":"lab-guides/lab5-ansible/run-playbooks/#next-steps","title":"Next Steps","text":"<p>Congratulations! You've successfully:</p> <ul> <li>Created Ansible inventory and variable files</li> <li>Written playbooks to configure and reset QoS settings</li> <li>Executed playbooks across multiple APIC controllers simultaneously</li> <li>Verified configuration changes through the APIC GUI</li> </ul> <p>This lab demonstrated Ansible's procedural approach to automation, complementing the declarative approaches shown in the Terraform labs. Each tool has its strengths and appropriate use cases in a comprehensive automation strategy.</p> <p>You've completed all labs! Proceed to the Conclusion for a workshop summary and next steps.</p>"},{"location":"lab-guides/lab5-ansible/setup-directory/","title":"Setup Directory Structure","text":""},{"location":"lab-guides/lab5-ansible/setup-directory/#create-ansible-directory","title":"Create Ansible Directory","text":"<p>Log in to the tools machine and create the <code>ansible</code> directory under <code>/opt/</code> then move to it:</p> <pre><code>mkdir /opt/ansible\ncd /opt/ansible\n</code></pre>"},{"location":"lab-guides/lab5-ansible/setup-directory/#create-subdirectories","title":"Create Subdirectories","text":"<p>Create the following subdirectories <code>group_vars</code> and <code>playbooks</code> underneath <code>ansible</code>:</p> <pre><code>mkdir group_vars\nmkdir playbooks\n</code></pre>"},{"location":"lab-guides/lab5-ansible/setup-directory/#directory-structure","title":"Directory Structure","text":"<p>Your final directory structure should look like this:</p> <pre><code>/opt/ansible/\n\u251c\u2500\u2500 inventory.ini\n\u251c\u2500\u2500 group_vars/\n\u2502   \u2514\u2500\u2500 apic.yml\n\u2514\u2500\u2500 playbooks/\n    \u251c\u2500\u2500 rocev2_qos.yml\n    \u2514\u2500\u2500 reset_qos.yml\n</code></pre> <p>This structure follows Ansible best practices:</p> <ul> <li>inventory.ini - Defines the APIC hosts to automate</li> <li>group_vars/ - Contains variables shared across host groups</li> <li>playbooks/ - Contains the automation playbooks</li> </ul> <p>Proceed to Inventory File.</p>"}]}